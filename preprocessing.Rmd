---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Preprocessing

```{r setup, include=FALSE}
WORDS_TO_IGNORE <- c("monozygotic", "XGBoost", "QCed")
source("knitr-options.R")
source("spelling-check.R")
library(bigsnpr)
```

In this chapter, I talk about conversion, quality control and imputation. Conversion is also discussed in \@ref(getting-bigsnp).

## Conversion and quality control of PLINK files {#PLINK}

PLINK is very efficient for conversion and quality control of multiple formats, so I provide some wrappers to PLINK in bigsnpr, for ease of use directly from R:

- `download_plink()` and `download_plink2()` for downloading the latest stable versions of PLINK 1.9 and 2.0 [@chang2015second].

- `snp_plinkQC()` for quality control (QC) and conversion to bed/bim/fam.

- `snp_plinkKINGQC()` for QC on relatedness based on KING-robust kinship estimator [@manichaikul2010robust]. Using `make.bed = FALSE` allows for computing related pairs only, i.e. reporting a data frame without producing new bed/bim/fam files. Note that monozygotic twins or identical samples have a KING coefficient of $0.5$, not $1$; $0.25$ = siblings and parents; $2^{-3}$ = second-degree relatives (e.g. grandparents, uncles); $2^{-4}$ = third-degree relatives (e.g. cousins). You can use a threshold of $2^{-4.5} \approx 0.0442$ to remove related individuals (PLINK removes one member of each pair of samples).
	
- `snp_plinkIBDQC()` for QC based on identity-by-descent (IBD) computed by PLINK using its method-of-moments. The KING one is supposed to be more robust.
	
- `snp_plinkRmSamples()` for producing new PLINK files after having removed some individuals.

- For any other PLINK function, I prefer calling PLINK directly from R thanks to system calls and R package glue, e.g.
    ```{r}
    plink <- download_plink("tmp-data")
    system(glue::glue(
      "{plink} --version"
    ))
    ```
    

## Imputation

Note that most functions from bigstatsr and bigsnpr do NOT handle missing values, except for some of the `bed_` functions.

Simple imputation (e.g. by the mean) of a 'double' FBM can be performed by blocks using e.g. the code from [this vignette](https://privefl.github.io/bigstatsr/articles/big-apply.html).

In bigsnpr, to perform simple imputation of genotyped data, you can use `snp_fastImputeSimple()`. You can also use the (much) slower `snp_fastImpute()` that uses XGBoost models to impute genotyped data [@prive2017efficient].
If you have access to imputed data from large external reference panels, it is even better, and you can read this data as dosages in a bigSNP as discussed in \@ref(getting-bigsnp).


## Example {#exo-preprocessing}

For the exercises, we will use the data provided in @reed2015guide.

This can be downloaded using 
```{r, warning=FALSE}
zip <- runonce::download_file(
  "https://figshare.com/ndownloader/files/38019072",
  dir = "tmp-data", fname = "GWAS_data.zip")
unzip(zip, exdir = "tmp-data", overwrite = FALSE)
```

For some reason, this data is not ordered by chromosome and position; we can use PLINK to get an ordered version of this using
```{r}
library(bigsnpr)
plink <- download_plink("tmp-data")
system(glue::glue(
  "{plink} --bfile tmp-data/GWAS_data",
  " --make-bed --out tmp-data/GWAS_data_sorted"
))
```

As you can see from PLINK output, this data contains 1401 individuals and 500,000 variants, with a small percentage of missing values (2.2%).

***

:::: {.infobox .exo}
Perform some QC with PLINK then read the QCed data as a bigSNP object in R.
::::

:::: {.infobox .caution}
Make sure to look at the documentation of functions before using them.
::::

<details>
<summary>Click to see solution</summary>

We can then perform some quality control using
```{r, include=FALSE}
file.remove(paste0("tmp-data/GWAS_data_sorted_QC", 
                   c(".bed", ".bim", ".fam", ".bk", ".rds")))
```
```{r}
bedfile2 <- snp_plinkQC(plink, "tmp-data/GWAS_data_sorted")
```
404,663 variants are remaining after this quality control.

:::: {.infobox .question}
How to control the amount of memory and number of threads used by PLINK?

Have a search at https://www.cog-genomics.org/plink/1.9/ using the quick index search at the bottom of the sidebar on the left.
::::

We can then read this data into an R object called `bigSNP` using
```{r}
(rds <- snp_readBed2(bedfile2, ncores = nb_cores()))
obj.bigsnp <- snp_attach(rds)
str(obj.bigsnp, max.level = 2)
```

</details>

***

We can read and store some extra information on the individuals (e.g. some phenotypes):
```{r}
clinical <- bigreadr::fread2("tmp-data/GWAS_clinical.csv")
str(clinical)
# Get the same order as for the genotypes
# (to match over multiple columns, use `vctrs::vec_match()`)
ord <- match(obj.bigsnp$fam$family.ID, clinical$FamID)
pheno <- clinical[ord, ]
# Quick check
stopifnot(all.equal(obj.bigsnp$fam$sex, pheno$sex))
# Update the $fam component
obj.bigsnp$fam <- cbind(obj.bigsnp$fam, pheno[-c(1, 3)])
```

:::: {.infobox .exo}
Use `dplyr::left_join()` on `obj.bigsnp$fam[1:6]` and `clinical` to get the same information as we have now in `obj.bigsnp$fam`. Which columns should you use to join from?
::::

<details>
<summary>Click to see solution</summary>

```{r}
str(obj.bigsnp$fam)
fam2 <- dplyr::left_join(obj.bigsnp$fam[1:6], clinical,
                         by = c("family.ID" = "FamID", "sex"))
str(fam2)
```

:::: {.infobox .caution}
Normally, `dplyr::left_join()` doesn't change the order of individuals from the first data frame (as opposed to `merge()`), but you can end up with more rows if there are duplicates in the second data frame.
::::

</details>

***

Recall that this data contains some missing values.

:::: {.infobox .exo}
Look at the number of missing values per variant using `big_counts()` and impute the data using `snp_fastImputeSimple()`.
::::

<details>
<summary>Click to see solution</summary>
```{r}
G <- obj.bigsnp$genotypes
counts <- big_counts(G)  # counts per variant
counts[, 1:8]
hist(nbNA <- counts[4, ])
```

We can e.g. perform a quick imputation by the mean using 
```{r}
G2 <- snp_fastImputeSimple(G, method = "mean2", ncores = nb_cores())
big_counts(G2, ind.col = 1:8)
big_counts(G, ind.col = 1:8)
```

:::: {.infobox .caution}
`G` still has missing values, but `G2` does not. Note that both use the same underlying data (the same binary file `.bk` on disk), the difference is that they use a different code to decode the underlying data:
::::

```{r}
G$code256
G2$code256
```

</details>

***

To always use `G2` (with the new `code256`) and the extended `obj.bigsnp$fam`, you need to save the new `obj.bigsnp` using
```{r}
obj.bigsnp$genotypes <- G2
snp_save(obj.bigsnp)
```

You can then re-attach this data in another R session later using `snp_attach("tmp-data/GWAS_data_sorted_QC.rds")`.  
