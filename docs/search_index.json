[["index.html", "Statistical Human Genetics course using R Originally a SMARTbiomed Summer course About Prerequisites License Author Contact", " Statistical Human Genetics course using R Originally a SMARTbiomed Summer course Florian Privé &amp; Isabelle McGrath 2025-06-10 About Prerequisites Have at least a basic knowledge of R, Install R (&gt;= 3.4) and RStudio (&gt;= 1.2), Install recent versions of {bigstatsr}, {bigsnpr}, and {susieR} (e.g. from CRAN), Download the data used in the tutorials: runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019072&quot;, dir = &quot;tmp-data&quot;, fname = &quot;GWAS_data.zip&quot;) # 109 MB runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019027&quot;, dir = &quot;tmp-data&quot;, fname = &quot;ref_freqs.csv.gz&quot;) # 46 MB runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019024&quot;, dir = &quot;tmp-data&quot;, fname = &quot;projection.csv.gz&quot;) # 44 MB runonce::download_file( &quot;https://figshare.com/ndownloader/files/38077323&quot;, dir = &quot;tmp-data&quot;, fname = &quot;sumstats_CAD_tuto.csv.gz&quot;) # 16 MB runonce::download_file( &quot;https://figshare.com/ndownloader/files/38247288&quot;, dir = &quot;tmp-data&quot;, fname = &quot;gen_pos_tuto.rds&quot;) # 2.5 MB bigsnpr::download_plink(&quot;tmp-data&quot;) # 6.3 MB bigsnpr::download_plink2(&quot;tmp-data&quot;) # 6.6 MB #&gt; [1] &quot;tmp-data/GWAS_data.zip&quot; #&gt; [1] &quot;tmp-data/ref_freqs.csv.gz&quot; #&gt; [1] &quot;tmp-data/projection.csv.gz&quot; #&gt; [1] &quot;tmp-data/sumstats_CAD_tuto.csv.gz&quot; #&gt; [1] &quot;tmp-data/gen_pos_tuto.rds&quot; #&gt; [1] &quot;tmp-data/plink.exe&quot; #&gt; [1] &quot;tmp-data/plink2.exe&quot; License This material is licensed under the Creative Commons Attribution-ShareAlike 3.0 License. Author Florian Privé is a senior researcher in statistical human genetics, fond of Data Science and an R(cpp) enthusiast. You can find him on Bluesky and GitHub as @privefl. Contact If you want me to add or clarify some content in this course, please open an issue on the GitHub repository of this course. If you have bug reports or questions specifically on functions of the packages, please open an issue on the corresponding package’s repository. I will always redirect you to GitHub issues if you email me about the packages, so that others can benefit from our discussion. "],["inputs-and-formats.html", "Chapter 1 Inputs and formats 1.1 Formats of genetic data 1.2 The bigSNP format from {bigsnpr} 1.3 Getting a bigSNP object 1.4 The FBM format from {bigstatsr} 1.5 Working with an FBM 1.6 Exercise", " Chapter 1 Inputs and formats 1.1 Formats of genetic data There exist many different data formats for genetic data: bed/bim/fam files (also called PLINK1 files) that respectively store genotype calls only (0, 1, 2, or NA) in a very condensed way (one byte only for 4 genotypes), information on the genetic variants, and information on the individuals. PLINK 1.9 and 2.0 provide many functions to work with this format. bgen files (usually one per chromosome) that can store imputed probabilities (P(0), P(1), P(2)) that are often transformed to dosage information (expected values: P(1) + 2 P(2)). Each variant is stored compressed, which is very efficient, especially for low-frequency variants. They are accompanied by bgen.bgi files that store information on the genetic variants and the position of their corresponding data in the bgen files, and by a sample file that stores information on the individual IDs. pgen files (also called PLINK2 files) that can store imputed data as well, and seem a bit more compressed than bgen files. PLINK2 provides many functions to work with this format. Many other formats that you can usually convert from using PLINK. 1.2 The bigSNP format from {bigsnpr} Package {bigsnpr} (Privé, Aschard, Ziyatdinov, &amp; Blum, 2018) uses a class called bigSNP for representing SNP data. A bigSNP object is merely a list with the three following elements: $genotypes: A FBM.code256. Rows are samples and columns are genetic variants. This stores genotype calls or dosages (rounded to 2 decimal places). More about this format below. $fam: A data.frame with some information on the samples. $map: A data.frame with some information on the genetic variants. The code used in class FBM.code256 for imputed data is e.g.  bigsnpr::CODE_DOSAGE #&gt; [1] 0.00 1.00 2.00 NA 0.00 1.00 2.00 0.00 0.01 0.02 0.03 0.04 0.05 0.06 #&gt; [15] 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20 #&gt; [29] 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 #&gt; [43] 0.35 0.36 0.37 0.38 0.39 0.40 0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 #&gt; [57] 0.49 0.50 0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.60 0.61 0.62 #&gt; [71] 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74 0.75 0.76 #&gt; [85] 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.90 #&gt; [99] 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99 1.00 1.01 1.02 1.03 1.04 #&gt; [113] 1.05 1.06 1.07 1.08 1.09 1.10 1.11 1.12 1.13 1.14 1.15 1.16 1.17 1.18 #&gt; [127] 1.19 1.20 1.21 1.22 1.23 1.24 1.25 1.26 1.27 1.28 1.29 1.30 1.31 1.32 #&gt; [141] 1.33 1.34 1.35 1.36 1.37 1.38 1.39 1.40 1.41 1.42 1.43 1.44 1.45 1.46 #&gt; [155] 1.47 1.48 1.49 1.50 1.51 1.52 1.53 1.54 1.55 1.56 1.57 1.58 1.59 1.60 #&gt; [169] 1.61 1.62 1.63 1.64 1.65 1.66 1.67 1.68 1.69 1.70 1.71 1.72 1.73 1.74 #&gt; [183] 1.75 1.76 1.77 1.78 1.79 1.80 1.81 1.82 1.83 1.84 1.85 1.86 1.87 1.88 #&gt; [197] 1.89 1.90 1.91 1.92 1.93 1.94 1.95 1.96 1.97 1.98 1.99 2.00 NA NA #&gt; [211] NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [225] NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [239] NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [253] NA NA NA NA where the first four elements are used to store genotype calls, the next three to store imputed allele counts, and the next 201 values to store dosages rounded to 2 decimal places. This allows for handling many data types (genotype calls and dosages) while storing each element using one byte only (x4 compared to bed files, but /8 compared to double-precision floating-point numbers). Package {bigsnpr} also provides functions for directly working on bed files with a small percentage of missing values (Privé, Luu, Blum, McGrath, &amp; Vilhjálmsson, 2020). 1.3 Getting a bigSNP object To read a bigSNP object from bed/bim/fam files, you can use functions snp_readBed() and snp_readBed2() (the second can read a subset of individuals/variants and use parallelism). To read dosages from BGEN files, you can use function snp_readBGEN(). This function takes around 40 minutes to read 1M variants for 400K individuals using 15 cores. Note that this function currently works only for BGEN v1.2 with probabilities stored as 8 bits (cf. this issue), which is the case for e.g. the UK Biobank files. To read any format used in genetics, you can always convert blocks of the data to text files using PLINK, read these using bigreadr::fread2(), and fill part of the resulting FBM. For example, see the code I used to convert the iPSYCH imputed data from the RICOPILI pipeline to my bigSNP format. Example converting a bed file to bigSNP: library(bigsnpr) #&gt; Loading required package: bigstatsr bedfile &lt;- system.file(&quot;extdata&quot;, &quot;example.bed&quot;, package = &quot;bigsnpr&quot;) (rds &lt;- snp_readBed2(bedfile, backingfile = tempfile())) # get path to new file #&gt; [1] &quot;C:\\\\Users\\\\au639593\\\\AppData\\\\Local\\\\Temp\\\\RtmpW8xJyl\\\\file1a5c41e14727.rds&quot; bigsnp &lt;- snp_attach(rds) # can then read in the bigSNP object in any R session (G &lt;- bigsnp$genotypes) #&gt; A Filebacked Big Matrix of type &#39;code 256&#39; with 517 rows and 4542 columns. G[1:5, 1:5] #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 0 2 0 1 #&gt; [2,] 1 0 1 0 0 #&gt; [3,] 0 1 1 0 2 #&gt; [4,] 0 0 2 0 2 #&gt; [5,] 1 0 0 0 2 str(bigsnp$fam) #&gt; &#39;data.frame&#39;: 517 obs. of 6 variables: #&gt; $ family.ID : chr &quot;POP1&quot; &quot;POP1&quot; &quot;POP1&quot; &quot;POP1&quot; ... #&gt; $ sample.ID : chr &quot;IND0&quot; &quot;IND1&quot; &quot;IND2&quot; &quot;IND3&quot; ... #&gt; $ paternal.ID: int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ maternal.ID: int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ sex : int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ affection : int 1 1 2 1 1 1 1 1 1 1 ... str(bigsnp$map) #&gt; &#39;data.frame&#39;: 4542 obs. of 6 variables: #&gt; $ chromosome : int 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ marker.ID : chr &quot;SNP0&quot; &quot;SNP1&quot; &quot;SNP2&quot; &quot;SNP3&quot; ... #&gt; $ genetic.dist: int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ physical.pos: int 112 1098 2089 3107 4091 5091 6107 7103 8090 9074 ... #&gt; $ allele1 : chr &quot;A&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; ... #&gt; $ allele2 : chr &quot;T&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... Example directly mapping the bed file: obj.bed &lt;- bed(bedfile) obj.bed[1:5, 1:5] #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 0 2 0 1 #&gt; [2,] 1 0 1 0 0 #&gt; [3,] 0 1 1 0 2 #&gt; [4,] 0 0 2 0 2 #&gt; [5,] 1 0 0 0 2 str(obj.bed$fam) #&gt; &#39;data.frame&#39;: 517 obs. of 6 variables: #&gt; $ family.ID : chr &quot;POP1&quot; &quot;POP1&quot; &quot;POP1&quot; &quot;POP1&quot; ... #&gt; $ sample.ID : chr &quot;IND0&quot; &quot;IND1&quot; &quot;IND2&quot; &quot;IND3&quot; ... #&gt; $ paternal.ID: int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ maternal.ID: int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ sex : int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ affection : int 1 1 2 1 1 1 1 1 1 1 ... str(obj.bed$map) #&gt; &#39;data.frame&#39;: 4542 obs. of 6 variables: #&gt; $ chromosome : int 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ marker.ID : chr &quot;SNP0&quot; &quot;SNP1&quot; &quot;SNP2&quot; &quot;SNP3&quot; ... #&gt; $ genetic.dist: int 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ physical.pos: int 112 1098 2089 3107 4091 5091 6107 7103 8090 9074 ... #&gt; $ allele1 : chr &quot;A&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; ... #&gt; $ allele2 : chr &quot;T&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... Example converting a bgen file to bigSNP: bgen &lt;- runonce::download_file( &quot;https://enkre.net/cgi-bin/code/bgen/raw/3ec770a829a753282b5cb45afc3f4eda036b246705b76f9037b6cc98c41a4194?at=example.8bits.bgen&quot;, fname = &quot;example.bgen&quot;) bgi &lt;- runonce::download_file( &quot;https://enkre.net/cgi-bin/code/bgen/raw/dc7276e0f0e2e096f58d2dac645aa5711de2cd64c3b29a07a80575e175344f78?at=example.8bits.bgen.bgi&quot;, fname = &quot;example.bgen.bgi&quot;) sample &lt;- runonce::download_file( &quot;https://enkre.net/cgi-bin/code/bgen/raw/a3c4d8e4c132048a502dc00a3e51362f98eda5a2889df695ba260dc48c327fd9?at=example.sample&quot;, fname = &quot;example.sample&quot;) # What should you be careful about when reading this file? readLines(sample, n = 5) #&gt; [1] &quot;ID_1&quot; &quot;0&quot; &quot;sample_001&quot; &quot;sample_002&quot; &quot;sample_003&quot; library(bigsnpr) (var_info &lt;- snp_readBGI(bgi)) #&gt; # A tibble: 199 × 8 #&gt; chromosome position rsid number_of_alleles allele1 allele2 #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 01 1001 RSID_101 2 A G #&gt; 2 01 2000 RSID_2 2 A G #&gt; 3 01 2001 RSID_102 2 A G #&gt; 4 01 3000 RSID_3 2 A G #&gt; 5 01 3001 RSID_103 2 A G #&gt; 6 01 4000 RSID_4 2 A G #&gt; 7 01 4001 RSID_104 2 A G #&gt; 8 01 5000 RSID_5 2 A G #&gt; 9 01 5001 RSID_105 2 A G #&gt; 10 01 6000 RSID_6 2 A G #&gt; # ℹ 189 more rows #&gt; # ℹ 2 more variables: file_start_position &lt;dbl&gt;, size_in_bytes &lt;int&gt; (snp_id &lt;- with(var_info[1:10, ], paste(chromosome, position, allele1, allele2, sep = &quot;_&quot;))) #&gt; [1] &quot;01_1001_A_G&quot; &quot;01_2000_A_G&quot; &quot;01_2001_A_G&quot; &quot;01_3000_A_G&quot; &quot;01_3001_A_G&quot; #&gt; [6] &quot;01_4000_A_G&quot; &quot;01_4001_A_G&quot; &quot;01_5000_A_G&quot; &quot;01_5001_A_G&quot; &quot;01_6000_A_G&quot; (rds &lt;- snp_readBGEN(bgen, backingfile = tempfile(), list_snp_id = list(snp_id))) #&gt; [1] &quot;C:\\\\Users\\\\au639593\\\\AppData\\\\Local\\\\Temp\\\\RtmpW8xJyl\\\\file1a5c64214029.rds&quot; bigsnp &lt;- snp_attach(rds) (G &lt;- bigsnp$genotypes) #&gt; A Filebacked Big Matrix of type &#39;code 256&#39; with 500 rows and 10 columns. str(bigsnp$map) # `$freq` and `$info` are computed when reading the data #&gt; tibble [10 × 8] (S3: tbl_df/tbl/data.frame) #&gt; $ chromosome : chr [1:10] &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; ... #&gt; $ marker.ID : chr [1:10] &quot;SNPID_101&quot; &quot;SNPID_2&quot; &quot;SNPID_102&quot; &quot;SNPID_3&quot; ... #&gt; $ rsid : chr [1:10] &quot;RSID_101&quot; &quot;RSID_2&quot; &quot;RSID_102&quot; &quot;RSID_3&quot; ... #&gt; $ physical.pos: int [1:10] 1001 2000 2001 3000 3001 4000 4001 5000 5001 6000 #&gt; $ allele1 : chr [1:10] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... #&gt; $ allele2 : chr [1:10] &quot;G&quot; &quot;G&quot; &quot;G&quot; &quot;G&quot; ... #&gt; $ freq : num [1:10] 0.583 0.802 0.198 0.483 0.517 ... #&gt; $ info : num [1:10] 0.975 0.668 0.666 0.952 0.952 ... There is no $fam information in this case, which should be read from other data and match using IDs from the sample file. 1.4 The FBM format from {bigstatsr} The format provided in package {bigstatsr} is called a Filebacked Big Matrix (FBM). It is an on-disk matrix format that is accessed through memory-mapping. How memory-mapping works: when you access the 1st element (1st row, 1st col), it accesses a block (say the first column) from disk into memory (RAM) when you access the 2nd element (2nd row, 1st col), it is already in memory so it is accessed very fast when you access the second column, you access from disk again (once) you can access many columns like that, until you do not have enough memory anymore some space is freed automatically so that new columns can be accessed into memory everything is seamlessly managed by the operating system (OS) it is also very convenient for parallelism as data is shared between processes All the elements of an FBM have the same type; supported types are: \"double\" (the default, double precision – 8 bytes per element) \"float\" (single precision – 4 bytes) \"integer\" (signed, so between \\(\\text{-}2^{31}\\) and (\\(2^{31} \\text{ - } 1\\)) – 4 bytes) \"unsigned short\": can store integer values from \\(0\\) to \\(65535\\) (2 bytes) \"raw\" or \"unsigned char\": can store integer values from \\(0\\) to \\(255\\) (1 byte). It is the basis for class FBM.code256 that can access 256 arbitrary different numeric values (decoded using a CODE_*), which is used in package {bigsnpr} (see above). 1.5 Working with an FBM 1.5.1 Similar accessor as R matrices library(bigstatsr) X &lt;- FBM(2, 5, init = 1:10, backingfile = &quot;tmp-data/test&quot;)$save() X$backingfile # the file where numeric data is stored #&gt; [1] &quot;C:\\\\Users\\\\au639593\\\\OneDrive - Aarhus universitet\\\\Desktop\\\\statgen-course\\\\tmp-data\\\\test.bk&quot; X$rds # the file where information about the data is stored #&gt; [1] &quot;C:\\\\Users\\\\au639593\\\\OneDrive - Aarhus universitet\\\\Desktop\\\\statgen-course\\\\tmp-data\\\\test.rds&quot; X &lt;- big_attach(&quot;tmp-data/test.rds&quot;) # can get the FBM from any R session You can access the whole FBM as an R matrix in memory using X[]. However, if the matrix is too large to fit in memory, you should always access only a subset of columns. Note that the elements of the FBM are stored column-wise (as for a standard R matrix). Therefore, be careful not to access a subset of rows, since it would read non-contiguous elements from the whole matrix from disk. X[, 1] # ok (must read first column only) #&gt; [1] 1 2 X[1, ] # bad (must read all data from disk) #&gt; [1] 1 3 5 7 9 X[] # super bad (standard R matrix in memory) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 3 5 7 9 #&gt; [2,] 2 4 6 8 10 1.5.2 Split-(par)Apply-Combine Strategy colSums(X[]) # super bad #&gt; [1] 3 7 11 15 19 Instead, the split-apply-combine strategy works well for applying standard R functions to FBMs (possibly in parallel), as implemented in big_apply(). Learn more with this tutorial on big_apply(). Compute the sum of each column of X &lt;- big_attachExtdata() using big_apply(). 1.5.3 Similar accessor as Rcpp matrices In case you want to develop new R functions for this format while coding in C++ (which is the case for many bigstatsr/bigsnpr functions). // [[Rcpp::plugins(cpp11)]] // [[Rcpp::depends(bigstatsr, rmio)]] #include &lt;bigstatsr/BMAcc.h&gt; // [[Rcpp::export]] NumericVector bigcolsums(Environment BM) { XPtr&lt;FBM&gt; xpBM = BM[&quot;address&quot;]; // get the external pointer BMAcc&lt;double&gt; macc(xpBM); // create an accessor to the data size_t n = macc.nrow(); // similar code as for an Rcpp::NumericMatrix size_t m = macc.ncol(); // similar code as for an Rcpp::NumericMatrix NumericVector res(m); for (size_t j = 0; j &lt; m; j++) for (size_t i = 0; i &lt; n; i++) res[j] += macc(i, j); // similar code as for an Rcpp::NumericMatrix return res; } For a subset of the data: // [[Rcpp::plugins(cpp11)]] // [[Rcpp::depends(bigstatsr, rmio)]] #include &lt;bigstatsr/BMAcc.h&gt; // [[Rcpp::export]] NumericVector bigcolsums2(Environment BM, const IntegerVector&amp; rowInd, const IntegerVector&amp; colInd) { XPtr&lt;FBM&gt; xpBM = BM[&quot;address&quot;]; // accessor to a sub-view of the data -&gt; the only line of code that should change SubBMAcc&lt;double&gt; macc(xpBM, rowInd, colInd, 1); size_t n = macc.nrow(); size_t m = macc.ncol(); NumericVector res(m); for (size_t j = 0; j &lt; m; j++) for (size_t i = 0; i &lt; n; i++) res[j] += macc(i, j); return res; } 1.5.4 Some summary functions are already implemented (X2 &lt;- snp_attachExtdata()$genotypes) #&gt; A Filebacked Big Matrix of type &#39;code 256&#39; with 517 rows and 4542 columns. big_colstats(X2) # sum and var (for each column) #&gt; sum var #&gt; 1 354 0.4604831 #&gt; 2 213 0.3241195 #&gt; 3 245 0.3932122 #&gt; 4 191 0.3109247 #&gt; 5 472 0.5176030 #&gt; 6 368 0.4613528 #&gt; 7 132 0.2292594 #&gt; 8 497 0.4791207 #&gt; 9 498 0.5160886 #&gt; 10 481 0.5416535 #&gt; 11 460 0.5168908 #&gt; 12 393 0.4772465 #&gt; 13 80 0.1465521 #&gt; 14 195 0.3245168 #&gt; 15 468 0.5084417 #&gt; 16 287 0.4489901 #&gt; 17 257 0.3745071 #&gt; 18 371 0.4356004 #&gt; 19 330 0.4444994 #&gt; 20 479 0.5178430 #&gt; 21 158 0.2707630 #&gt; 22 389 0.4540881 #&gt; 23 335 0.4882371 #&gt; 24 394 0.4801104 #&gt; 25 430 0.4968213 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 4517 rows ] big_scale()(X2) # mean and sd (for each column) #&gt; center scale #&gt; 1 0.6847195 0.6785891 #&gt; 2 0.4119923 0.5693149 #&gt; 3 0.4738878 0.6270663 #&gt; 4 0.3694391 0.5576062 #&gt; 5 0.9129594 0.7194463 #&gt; 6 0.7117988 0.6792295 #&gt; 7 0.2553191 0.4788104 #&gt; 8 0.9613153 0.6921855 #&gt; 9 0.9632495 0.7183931 #&gt; 10 0.9303675 0.7359712 #&gt; 11 0.8897485 0.7189512 #&gt; 12 0.7601547 0.6908303 #&gt; 13 0.1547389 0.3828213 #&gt; 14 0.3771760 0.5696638 #&gt; 15 0.9052224 0.7130510 #&gt; 16 0.5551257 0.6700673 #&gt; 17 0.4970986 0.6119698 #&gt; 18 0.7176015 0.6600003 #&gt; 19 0.6382979 0.6667079 #&gt; 20 0.9264990 0.7196131 #&gt; 21 0.3056093 0.5203490 #&gt; 22 0.7524178 0.6738606 #&gt; 23 0.6479691 0.6987397 #&gt; 24 0.7620890 0.6929000 #&gt; 25 0.8317215 0.7048555 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 4517 rows ] snp_scaleBinom()(X2) # 2 * af (mean) and sqrt(2 * af * (1 - af)) (~sd) #&gt; center scale #&gt; 1 0.6847195 0.6710433 #&gt; 2 0.4119923 0.5719471 #&gt; 3 0.4738878 0.6013343 #&gt; 4 0.3694391 0.5488137 #&gt; 5 0.9129594 0.7044231 #&gt; 6 0.7117988 0.6771042 #&gt; 7 0.2553191 0.4719377 #&gt; 8 0.9613153 0.7065775 #&gt; 9 0.9632495 0.7066291 #&gt; 10 0.9303675 0.7053904 #&gt; 11 0.8897485 0.7027961 #&gt; 12 0.7601547 0.6864671 #&gt; 13 0.1547389 0.3778450 #&gt; 14 0.3771760 0.5532135 #&gt; 15 0.9052224 0.7039237 #&gt; 16 0.5551257 0.6332799 #&gt; 17 0.4970986 0.6111834 #&gt; 18 0.7176015 0.6783256 #&gt; 19 0.6382979 0.6592312 #&gt; 20 0.9264990 0.7051942 #&gt; 21 0.3056093 0.5088327 #&gt; 22 0.7524178 0.6850923 #&gt; 23 0.6479691 0.6618437 #&gt; 24 0.7620890 0.6868036 #&gt; 25 0.8317215 0.6970231 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 4517 rows ] Functions starting with big_ are part of {bigstatsr} and work for any type of FBM, while functions starting with snp_ or bed_ are part of {bigsnpr} and are more specific to genetic data. There are now many functions implemented in the packages. You can find a comprehensive list of available functions on the package website of {bigstatsr} and of {bigsnpr}. What is the difference between functions starting with snp_ vs bed_? To only use a subset of the data stored as an FBM, you should almost never make a copy of the data; instead, use parameters ind.row (or ind.train) and ind.col to apply functions to a subset of the data. 1.6 Exercise zip &lt;- runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019072&quot;, dir = &quot;tmp-data&quot;, fname = &quot;GWAS_data.zip&quot;) unzip(zip, exdir = &quot;tmp-data&quot;, overwrite = FALSE) bedfile &lt;- &quot;tmp-data/GWAS_data.bed&quot; Map this data with bed() and start exploring it a bit, e.g. what summaries you could compute, what functions you could use. References Privé, F., Aschard, H., Ziyatdinov, A., &amp; Blum, M.G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34, 2781–2787. Privé, F., Luu, K., Blum, M.G., McGrath, J.J., &amp; Vilhjálmsson, B.J. (2020). Efficient toolkit implementing best practices for principal component analysis of population genetic data. Bioinformatics, 36, 4449–4457. "],["preprocessing.html", "Chapter 2 Preprocessing 2.1 Conversion and quality control of PLINK files 2.2 Imputation 2.3 Example", " Chapter 2 Preprocessing In this section, I talk about conversion, quality control and imputation. Conversion is also discussed in 1.3. 2.1 Conversion and quality control of PLINK files PLINK is very efficient for conversion and quality control of multiple formats, so I provide some wrappers to PLINK in {bigsnpr}, for ease of use directly from R: download_plink() and download_plink2() for downloading the latest stable versions of PLINK 1.9 and 2.0 (Chang et al., 2015). snp_plinkQC() for quality control (QC) and conversion to bed/bim/fam. snp_plinkKINGQC() for QC on relatedness based on KING-robust kinship estimator (Manichaikul et al., 2010). Using make.bed = FALSE allows for computing related pairs only, i.e. reporting a data frame without producing new bed/bim/fam files. Note that monozygotic twins or identical samples have a KING coefficient of \\(0.5\\), not \\(1\\); \\(0.25\\) = siblings and parents; \\(2^{-3}\\) = second-degree relatives (e.g. grandparents, uncles); \\(2^{-4}\\) = third-degree relatives (e.g. cousins). You can use a threshold of \\(2^{-4.5} \\approx 0.0442\\) to remove all these related individuals (one from each pair, or all for PCA). snp_plinkIBDQC() for QC based on identity-by-descent (IBD) computed by PLINK using its method-of-moments. I prefer the KING one. snp_plinkRmSamples() for producing new PLINK files after having removed some individuals. For any other PLINK function, I prefer calling PLINK directly from R thanks to system calls and package {glue}, e.g. plink &lt;- download_plink(&quot;tmp-data&quot;) system(glue::glue( &quot;{plink} --version&quot; )) #&gt; PLINK v1.9.0-b.7.7 64-bit (22 Oct 2024) 2.2 Imputation Note that most functions from {bigstatsr} and {bigsnpr} do NOT handle missing values, except for some of the bed_ functions. Simple imputation (e.g. by the mean) of a ‘double’ FBM can be performed by blocks using e.g. the code from this vignette. In {bigsnpr}, to perform simple imputation of genotyped data, you can use snp_fastImputeSimple(). You can also use the (much) slower snp_fastImpute() that uses XGBoost models to impute genotyped data (Privé et al., 2018). If you have access to imputed data from large external reference panels, it is even better, and you can read this data as dosages in a bigSNP as discussed in 1.3. 2.3 Example For the exercises, we will use the data provided in Reed et al. (2015). This can be downloaded using zip &lt;- runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019072&quot;, dir = &quot;tmp-data&quot;, fname = &quot;GWAS_data.zip&quot;) unzip(zip, exdir = &quot;tmp-data&quot;, overwrite = FALSE) For some reason, this data is not ordered by chromosome and position; we can use PLINK to get an ordered version of this using library(bigsnpr) plink &lt;- download_plink(&quot;tmp-data&quot;) system(glue::glue( &quot;{plink} --bfile tmp-data/GWAS_data&quot;, &quot; --make-bed --out tmp-data/GWAS_data_sorted&quot; )) #&gt; PLINK v1.9.0-b.7.7 64-bit (22 Oct 2024) cog-genomics.org/plink/1.9/ #&gt; (C) 2005-2024 Shaun Purcell, Christopher Chang GNU General Public License v3 #&gt; Logging to tmp-data/GWAS_data_sorted.log. #&gt; Options in effect: #&gt; --bfile tmp-data/GWAS_data #&gt; --make-bed #&gt; --out tmp-data/GWAS_data_sorted #&gt; #&gt; 32574 MB RAM detected; reserving 16287 MB for main workspace. #&gt; 500000 variants loaded from .bim file. #&gt; 1401 people (937 males, 464 females) loaded from .fam. #&gt; 933 phenotype values loaded from .fam. #&gt; Using 1 thread (no multithreaded calculations invoked). #&gt; Before main variant filters, 1401 founders and 0 nonfounders present. #&gt; Calculating allele frequencies... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\b\b done. #&gt; Total genotyping rate is 0.977593. #&gt; 500000 variants and 1401 people pass filters and QC. #&gt; Among remaining phenotypes, 463 are cases and 470 are controls. (468 #&gt; phenotypes are missing.) #&gt; --make-bed to tmp-data/GWAS_data_sorted.bed + tmp-data/GWAS_data_sorted.bim + #&gt; tmp-data/GWAS_data_sorted.fam ... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\bdone. As you can see from PLINK output, this data contains 1401 individuals and 500,000 variants, with a small percentage of missing values (2.2%). Perform some QC with PLINK then read the QCed data as a bigSNP object in R. Make sure to look at the documentation of functions before using them. Click to see solution We can then perform some quality control using bedfile2 &lt;- snp_plinkQC(plink, &quot;tmp-data/GWAS_data_sorted&quot;) #&gt; PLINK v1.9.0-b.7.7 64-bit (22 Oct 2024) cog-genomics.org/plink/1.9/ #&gt; (C) 2005-2024 Shaun Purcell, Christopher Chang GNU General Public License v3 #&gt; Logging to tmp-data/GWAS_data_sorted_QC.log. #&gt; Options in effect: #&gt; --bfile tmp-data/GWAS_data_sorted #&gt; --geno 0.1 #&gt; --hwe 1e-50 #&gt; --maf 0.01 #&gt; --make-bed #&gt; --mind 0.1 #&gt; --out tmp-data/GWAS_data_sorted_QC #&gt; #&gt; 32574 MB RAM detected; reserving 16287 MB for main workspace. #&gt; 500000 variants loaded from .bim file. #&gt; 1401 people (937 males, 464 females) loaded from .fam. #&gt; 933 phenotype values loaded from .fam. #&gt; 0 people removed due to missing genotype data (--mind). #&gt; Using 1 thread (no multithreaded calculations invoked). #&gt; Before main variant filters, 1401 founders and 0 nonfounders present. #&gt; Calculating allele frequencies... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\b\b done. #&gt; Total genotyping rate is 0.977593. #&gt; 27390 variants removed due to missing genotype data (--geno). #&gt; --hwe: 91 variants removed due to Hardy-Weinberg exact test. #&gt; 67856 variants removed due to minor allele threshold(s) #&gt; (--maf/--max-maf/--mac/--max-mac). #&gt; 404663 variants and 1401 people pass filters and QC. #&gt; Among remaining phenotypes, 463 are cases and 470 are controls. (468 #&gt; phenotypes are missing.) #&gt; --make-bed to tmp-data/GWAS_data_sorted_QC.bed + #&gt; tmp-data/GWAS_data_sorted_QC.bim + tmp-data/GWAS_data_sorted_QC.fam ... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\bdone. 404,663 variants are remaining after this quality control. How to control the amount of memory and number of threads used by PLINK? Have a search at https://www.cog-genomics.org/plink/1.9/ using the quick index search at the bottom of the sidebar on the left. We can then read this data into an R object called bigSNP using (rds &lt;- snp_readBed2(bedfile2, ncores = nb_cores())) #&gt; [1] &quot;C:\\\\Users\\\\au639593\\\\OneDrive - Aarhus universitet\\\\Desktop\\\\statgen-course\\\\tmp-data\\\\GWAS_data_sorted_QC.rds&quot; obj.bigsnp &lt;- snp_attach(rds) str(obj.bigsnp, max.level = 2) #&gt; List of 3 #&gt; $ genotypes:Reference class &#39;FBM.code256&#39; [package &quot;bigstatsr&quot;] with 16 fields #&gt; ..and 26 methods, of which 12 are possibly relevant: #&gt; .. add_columns, as.FBM, bm, bm.desc, check_dimensions, #&gt; .. check_write_permissions, copy#envRefClass, initialize, #&gt; .. initialize#FBM, save, show#envRefClass, show#FBM #&gt; $ fam :&#39;data.frame&#39;: 1401 obs. of 6 variables: #&gt; ..$ family.ID : int [1:1401] 10002 10004 10005 10007 10008 10009 10010 10011 10012 10013 ... #&gt; ..$ sample.ID : int [1:1401] 1 1 1 1 1 1 1 1 1 1 ... #&gt; ..$ paternal.ID: int [1:1401] 0 0 0 0 0 0 0 0 0 0 ... #&gt; ..$ maternal.ID: int [1:1401] 0 0 0 0 0 0 0 0 0 0 ... #&gt; ..$ sex : int [1:1401] 1 2 1 1 1 1 1 2 1 2 ... #&gt; ..$ affection : int [1:1401] 1 1 2 1 2 2 2 1 2 -9 ... #&gt; $ map :&#39;data.frame&#39;: 404663 obs. of 6 variables: #&gt; ..$ chromosome : int [1:404663] 1 1 1 1 1 1 1 1 1 1 ... #&gt; ..$ marker.ID : chr [1:404663] &quot;rs12565286&quot; &quot;rs3094315&quot; &quot;rs2980319&quot; &quot;rs2980300&quot; ... #&gt; ..$ genetic.dist: int [1:404663] 0 0 0 0 0 0 0 0 0 0 ... #&gt; ..$ physical.pos: int [1:404663] 721290 752566 777122 785989 798959 947034 949608 1018704 1041700 1129672 ... #&gt; ..$ allele1 : chr [1:404663] &quot;G&quot; &quot;C&quot; &quot;A&quot; &quot;A&quot; ... #&gt; ..$ allele2 : chr [1:404663] &quot;C&quot; &quot;T&quot; &quot;T&quot; &quot;G&quot; ... #&gt; - attr(*, &quot;class&quot;)= chr &quot;bigSNP&quot; We can read and store some extra information on the individuals (e.g. some phenotypes): clinical &lt;- bigreadr::fread2(&quot;tmp-data/GWAS_clinical.csv&quot;) str(clinical) #&gt; &#39;data.frame&#39;: 1401 obs. of 7 variables: #&gt; $ FamID: int 10002 10004 10005 10007 10008 10009 10010 10011 10012 10013 ... #&gt; $ CAD : int 1 1 1 1 1 1 1 1 1 0 ... #&gt; $ sex : int 1 2 1 1 1 1 1 2 1 2 ... #&gt; $ age : int 60 50 55 52 58 59 54 66 58 67 ... #&gt; $ tg : int NA 55 105 314 161 171 147 124 60 160 ... #&gt; $ hdl : int NA 23 37 54 40 46 69 47 114 40 ... #&gt; $ ldl : int NA 75 69 108 94 92 109 84 67 112 ... # Get the same order as for the genotypes # (to match over multiple columns, use `vctrs::vec_match()`) ord &lt;- match(obj.bigsnp$fam$family.ID, clinical$FamID) pheno &lt;- clinical[ord, ] # Quick check stopifnot(all.equal(obj.bigsnp$fam$sex, pheno$sex)) # Update the $fam component (could have used `dplyr::left_join()` also) obj.bigsnp$fam &lt;- cbind(obj.bigsnp$fam, pheno[-c(1, 3)]) Recall that this data contains some missing values. Look at the number of missing values per variant using big_counts() and impute the data using snp_fastImputeSimple(). Click to see solution G &lt;- obj.bigsnp$genotypes counts &lt;- big_counts(G) # counts per variant counts[, 1:8] #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #&gt; 0 1247 958 1057 988 831 1201 496 386 #&gt; 1 131 362 316 370 502 115 676 730 #&gt; 2 6 66 28 25 67 7 165 216 #&gt; &lt;NA&gt; 17 15 0 18 1 78 64 69 hist(nbNA &lt;- counts[4, ]) We can e.g. perform a quick imputation by the mean using G2 &lt;- snp_fastImputeSimple(G, method = &quot;mean2&quot;, ncores = nb_cores()) big_counts(G2, ind.col = 1:8) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #&gt; 0 1247 958 1057 988 831 1201 496 386 #&gt; 1 131 362 316 370 502 115 676 730 #&gt; 2 6 66 28 25 67 7 165 216 #&gt; &lt;NA&gt; 0 0 0 0 0 0 0 0 #&gt; 0.01 0 0 0 0 0 0 0 0 #&gt; 0.02 0 0 0 0 0 0 0 0 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 196 rows ] big_counts(G, ind.col = 1:8) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #&gt; 0 1247 958 1057 988 831 1201 496 386 #&gt; 1 131 362 316 370 502 115 676 730 #&gt; 2 6 66 28 25 67 7 165 216 #&gt; &lt;NA&gt; 17 15 0 18 1 78 64 69 G still has missing values, but G2 does not. Note that both use the same underlying data (the same binary file .bk on disk), the difference is that they use a different code to decode the underlying data: G$code256 #&gt; [1] 0 1 2 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [24] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA #&gt; [47] NA NA NA NA #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 206 entries ] G2$code256 #&gt; [1] 0.00 1.00 2.00 NA 0.00 1.00 2.00 0.00 0.01 0.02 0.03 0.04 0.05 0.06 #&gt; [15] 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20 #&gt; [29] 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 #&gt; [43] 0.35 0.36 0.37 0.38 0.39 0.40 0.41 0.42 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 206 entries ] To always use G2 (with the new code256) and the extended obj.bigsnp$fam, you need to save the new obj.bigsnp using obj.bigsnp$genotypes &lt;- G2 snp_save(obj.bigsnp) You can then re-attach this data in another R session later using snp_attach(\"tmp-data/GWAS_data_sorted_QC.rds\"). References Chang, C.C., Chow, C.C., Tellier, L.C., Vattikuti, S., Purcell, S.M., &amp; Lee, J.J. (2015). Second-generation PLINK: Rising to the challenge of larger and richer datasets. Gigascience, 4, s13742–015. Manichaikul, A., Mychaleckyj, J.C., Rich, S.S., Daly, K., Sale, M., &amp; Chen, W.-M. (2010). Robust relationship inference in genome-wide association studies. Bioinformatics, 26, 2867–2873. Privé, F., Aschard, H., Ziyatdinov, A., &amp; Blum, M.G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34, 2781–2787. Reed, E., Nunez, S., Kulp, D., Qian, J., Reilly, M.P., &amp; Foulkes, A.S. (2015). A guide to genome-wide association analysis and post-analytic interrogation. Statistics in Medicine, 34, 3769–3792. "],["population-structure.html", "Chapter 3 Population structure 3.1 Principal Component Analysis (PCA) 3.2 The problem with LD 3.3 Best practices for PCA of genetic data 3.4 Exercise 3.5 Ancestry inference", " Chapter 3 Population structure 3.1 Principal Component Analysis (PCA) PCA on the genotype matrix can be used to capture population structure. However, PCA can actually capture different kinds of structure (Privé, Luu, Blum, et al., 2020): population structure (what we want), Linkage Disequilibrium (LD) structure, when there are two many correlated variants (e.g. within long-range LD regions) and not enough population structure (see this vignette), relatedness structure, when there are related individuals who usually cluster together in later PCs, noise, basically just circles when looking at PC scores. Population structure is the second main topic of my research work (after polygenic scores). In Privé et al. (2018), I introduced an algorithm to compute PCA for a bigSNP object while accounting for the LD problem by using clumping (not pruning, cf. this vignette) and an automatic detection and removal of long-range LD regions. In Privé, Luu, Vilhjálmsson, &amp; Blum (2020), I improved the implementation of the pcadapt algorithm, which detects variants associated with population structure (i.e. some kind of GWAS for population structure). In Privé, Luu, Blum, et al. (2020), I extended {bigsnpr} to also be able to run PCA on PLINK bed files directly with a small percentage of missing values, and investigated best practices for PCA in more detail. In Privé et al. (2022) and Privé (2022), I showed how to use PCA for ancestry inference, including grouping individuals in homogeneous ancestry groups, and inferring ancestry proportions from genotype data but also from allele frequencies only (see this vignette). 3.2 The problem with LD Let us reuse the data prepared in 2.3. library(ggplot2) library(bigsnpr) #&gt; Loading required package: bigstatsr bigsnp &lt;- snp_attach(&quot;tmp-data/GWAS_data_sorted_QC.rds&quot;) G &lt;- bigsnp$genotypes NCORES &lt;- nb_cores() Use big_randomSVD() to perform a SVD/PCA on G. Do not forget to use some scaling (at least some centering). Look at PC scores and PC loadings with plot(). What do you see for PC4? Click to see solution svd &lt;- runonce::save_run( big_randomSVD(G, fun.scaling = big_scale(), ncores = NCORES), file = &quot;tmp-data/svd_with_ld.rds&quot;) #&gt; user system elapsed #&gt; 0.73 0.27 59.08 #&gt; Code finished running at 2025-06-10 13:33:51 CEST plot(svd) plot(svd, type = &quot;scores&quot;) plot(svd, type = &quot;scores&quot;, scores = 3:4) plot(svd, type = &quot;loadings&quot;, loadings = 1:10, coef = 0.4) What is going on with PC4? the_max &lt;- which.max(abs(svd$v[, 4])) plot(svd, type = &quot;scores&quot;, scores = 3:4) + aes(color = as.factor(G[, the_max])) + labs(color = &quot;One geno&quot;) PC4 is basically capturing variation in a block of LD and is then very correlated to genetic variants in this region. You really want to avoid using this type of PCs e.g. as covariates in GWAS because it will cause some collider bias. To avoid capturing LD in PCA, it has been recommended to perform some pruning (removing variants too correlated with one another) AND remove some known list of long-range LD regions (that can be captured by PCA, even after a stringent pruning step). But this is not enough… This is exactly what the UK Biobank did, and this how the PC loadings of the 40 PCs they provide look like: I recommend using only the first 16 PCs provided by the UK Biobank (Privé, Luu, Blum, et al., 2020). 3.3 Best practices for PCA of genetic data There can be many steps to properly perform a PCA; you can find more about this in Privé, Luu, Blum, et al. (2020). Let’s have a look at the corresponding tutorial from the bigsnpr website. 3.4 Exercise Let us reuse the data prepared in 2.3. Follow the previous tutorial to perform a PCA for this data, either using snp_* functions on the bigSNP object or bed_* functions on the bed file mapped. Click to see solution First, let us get an idea of the relatedness in the data using library(bigsnpr) (NCORES &lt;- nb_cores()) plink2 &lt;- download_plink2(&quot;tmp-data&quot;) rel &lt;- snp_plinkKINGQC(plink2, &quot;tmp-data/GWAS_data_sorted_QC.bed&quot;, thr.king = 2^-4.5, make.bed = FALSE, ncores = NCORES) hist(log2(rel$KINSHIP), &quot;FD&quot;); abline(v = c(-4.5, -3.5), col = &quot;red&quot;) When computing relatedness with KING, LD pruning is NOT recommended. However, it may be useful to filter out some variants that are highly associated with population structure, e.g. as performed in the UK Biobank (Bycroft et al., 2018). For example, see this code. Relatedness should not be a major issue here. Let us now compute PCs. All the code that follows could be run on the bigSNP object we made before. Nevertheless, to showcase the bed_* functions here, we will run the following analyses on the bed file directly. # Memory-map a bed file directly obj.bed &lt;- bed(&quot;tmp-data/GWAS_data_sorted_QC.bed&quot;) obj.svd &lt;- runonce::save_run( bed_autoSVD(obj.bed, k = 12, ncores = NCORES), file = &quot;tmp-data/PCA_GWAS_data.rds&quot;) #&gt; Discarding 11041 variants with MAC &lt; 10 or MAF &lt; 0.02. #&gt; #&gt; Phase of clumping (on MAC) at r^2 &gt; 0.2.. keep 109328 variants. #&gt; #&gt; Iteration 1: #&gt; Computing SVD.. #&gt; 399 outlier variants detected.. #&gt; 3 long-range LD regions detected.. #&gt; #&gt; Iteration 2: #&gt; Computing SVD.. #&gt; 10 outlier variants detected.. #&gt; 0 long-range LD region detected.. #&gt; #&gt; Iteration 3: #&gt; Computing SVD.. #&gt; 0 outlier variant detected.. #&gt; #&gt; Converged! #&gt; user system elapsed #&gt; 80.42 1.28 392.85 #&gt; Code finished running at 2025-06-10 13:41:05 CEST plot(obj.svd) plot(obj.svd, type = &quot;scores&quot;, scores = 1:12, coeff = 0.5) There is some population structure (maybe up to 6 PCs). You should also check loadings to make sure there is no LD structure (peaks on loadings): plot(obj.svd, type = &quot;loadings&quot;, loadings = 1:6, coeff = 0.5) No peaks, but loadings of PC4 and PC5 are a bit odd. If you expect the individuals to mostly come from one population (e.g. in a national biobank), you can simply use a robust distance to identify a homogeneous subset of individuals, then look at the histogram of log-distances to choose a threshold based on visual inspection (here I would probably choose 4.5). PC &lt;- predict(obj.svd) ldist &lt;- log(bigutilsr::dist_ogk(PC[, 1:6])) hist(ldist, &quot;FD&quot;) library(ggplot2) source(&quot;https://raw.githubusercontent.com/privefl/paper4-bedpca/master/code/plot_grid2.R&quot;) plot_grid2(plotlist = lapply(1:4, function(k) { k1 &lt;- 2 * k - 1 k2 &lt;- 2 * k qplot(PC[, k1], PC[, k2], color = ldist, size = I(2)) + scale_color_viridis_c() + theme_bigstatsr(0.6) + labs(x = paste0(&quot;PC&quot;, k1), y = paste0(&quot;PC&quot;, k2), color = &quot;log-distance&quot;) + coord_equal() }), nrow = 2, legend_ratio = 0.2, title_ratio = 0) #&gt; Warning: `qplot()` was deprecated in ggplot2 3.4.0. #&gt; This warning is displayed once every 8 hours. #&gt; Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #&gt; generated. #&gt; Warning in get_plot_component(plot, &quot;guide-box&quot;): Multiple components #&gt; found; returning the first one. To return all, use `return_all = TRUE`. 3.5 Ancestry inference It would be nice if we could get a better sense of the ancestry of these individuals. To achieve this, we can project this data onto the PCA space of many known population groups defined in Privé (2022). all_freq &lt;- bigreadr::fread2( runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019027&quot;, # for the tutorial (46 MB) # &quot;https://figshare.com/ndownloader/files/31620968&quot;, # for real analyses (849 MB) dir = &quot;tmp-data&quot;, fname = &quot;ref_freqs.csv.gz&quot;)) projection &lt;- bigreadr::fread2( runonce::download_file( &quot;https://figshare.com/ndownloader/files/38019024&quot;, # for the tutorial (44 MB) # &quot;https://figshare.com/ndownloader/files/31620953&quot;, # for real analyses (847 MB) dir = &quot;tmp-data&quot;, fname = &quot;projection.csv.gz&quot;)) # coefficients to correct for overfitting of PCA correction &lt;- c(1, 1, 1, 1.008, 1.021, 1.034, 1.052, 1.074, 1.099, 1.123, 1.15, 1.195, 1.256, 1.321, 1.382, 1.443) # match variants between the two datasets library(dplyr) matched &lt;- obj.bed$map %&gt;% transmute(chr = chromosome, pos = physical.pos, a1 = allele1, a0 = allele2) %&gt;% mutate(beta = 1) %&gt;% snp_match(all_freq[1:5]) %&gt;% print() #&gt; chr pos a0 a1 beta _NUM_ID_.ss rsid _NUM_ID_ #&gt; 1 1 752566 G A -1 2 rs3094315 1 #&gt; 2 1 785989 T C -1 4 rs2980300 2 #&gt; 3 1 798959 G A 1 5 rs11240777 3 #&gt; 4 1 947034 G A -1 6 rs2465126 4 #&gt; 5 1 949608 G A 1 7 rs1921 5 #&gt; 6 1 1018704 A G -1 8 rs9442372 6 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 301150 rows ] # further subsetting on missing values counts &lt;- bed_counts(obj.bed, ind.col = matched$`_NUM_ID_.ss`, ncores = NCORES) # hist(nb_na &lt;- counts[4, ]) ind &lt;- which(counts[4, ] &lt; (nrow(obj.bed) * 0.05)) # project individuals (divided by 2) onto the PC space PROJ &lt;- as.matrix(projection[matched$`_NUM_ID_`[ind], -(1:5)]) all_proj &lt;- apply(sweep(PROJ, 2, correction / 2, &#39;*&#39;), 2, function(x) { bed_prodVec(obj.bed, x, ind.col = matched$`_NUM_ID_.ss`[ind], ncores = NCORES, # scaling to get G if beta = 1 and (2 - G) if beta = -1 center = 1 - matched$beta[ind], scale = matched$beta[ind]) }) We can then assign individuals to the closest center: all_centers &lt;- crossprod(as.matrix(all_freq[matched$`_NUM_ID_`[ind], -(1:5)]), PROJ) all_sq_dist &lt;- apply(all_centers, 1, function(one_center) { rowSums(sweep(all_proj, 2, one_center, &#39;-&#39;)^2) }) THR &lt;- 0.002 # you can adjust this threshold thr_sq_dist &lt;- max(dist(all_centers)^2) * THR / 0.16 group &lt;- colnames(all_freq)[-(1:5)] group[group %in% c(&quot;Scandinavia&quot;, &quot;United Kingdom&quot;, &quot;Ireland&quot;)] &lt;- &quot;Europe (North West)&quot; group[group %in% c(&quot;Europe (South East)&quot;, &quot;Europe (North East)&quot;)] &lt;- &quot;Europe (East)&quot; cluster &lt;- apply(all_sq_dist, 1, function(sq_dist) { ind &lt;- which.min(sq_dist) if (sq_dist[ind] &lt; thr_sq_dist) group[ind] else NA }) table(cluster, exclude = NULL) # 3 NAs -&gt; almost all assigned #&gt; cluster #&gt; Ashkenazi Europe (East) Europe (North West) #&gt; 110 148 872 #&gt; Europe (South West) Italy Middle East #&gt; 45 219 4 #&gt; &lt;NA&gt; #&gt; 3 plot_grid2(plotlist = lapply(1:4, function(k) { k1 &lt;- 2 * k - 1 k2 &lt;- 2 * k qplot(PC[, k1], PC[, k2], color = cluster, size = I(2)) + theme_bigstatsr(0.6) + labs(x = paste0(&quot;PC&quot;, k1), y = paste0(&quot;PC&quot;, k2), color = &quot;Assigned\\npopulation&quot;) + coord_equal() }), nrow = 2, legend_ratio = 0.25, title_ratio = 0) #&gt; Warning in get_plot_component(plot, &quot;guide-box&quot;): Multiple components #&gt; found; returning the first one. To return all, use `return_all = TRUE`. These are mostly European individuals. PC4-PC6 are definitively a bit odd. References Bycroft, C., Freeman, C., Petkova, D., Band, G., Elliott, L.T., Sharp, K., et al. (2018). The UK Biobank resource with deep phenotyping and genomic data. Nature, 562, 203–209. Privé, F. (2022). Using the UK Biobank as a global reference of worldwide populations: application to measuring ancestry diversity from GWAS summary statistics. Bioinformatics, 38, 3477–3480. Privé, F., Aschard, H., Carmi, S., Folkersen, L., Hoggart, C., O’Reilly, P.F., &amp; Vilhjálmsson, B.J. (2022). Portability of 245 polygenic scores when derived from the UK Biobank and applied to 9 ancestry groups from the same cohort. The American Journal of Human Genetics, 109, 12–23. Privé, F., Aschard, H., Ziyatdinov, A., &amp; Blum, M.G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34, 2781–2787. Privé, F., Luu, K., Blum, M.G., McGrath, J.J., &amp; Vilhjálmsson, B.J. (2020). Efficient toolkit implementing best practices for principal component analysis of population genetic data. Bioinformatics, 36, 4449–4457. Privé, F., Luu, K., Vilhjálmsson, B.J., &amp; Blum, M.G. (2020). Performing highly efficient genome scans for local adaptation with R package pcadapt version 4. Molecular Biology and Evolution, 37, 2153–2154. "],["genome-wide-association-study-gwas.html", "Chapter 4 Genome-Wide Association Study (GWAS) 4.1 Example", " Chapter 4 Genome-Wide Association Study (GWAS) In {bigstatsr}, you can perform both standard linear and logistic regressions GWAS, using either big_univLinReg() or big_univLogReg(). Function big_univLinReg() should be very fast, while big_univLogReg() is slower. This type of association, where each variable is considered independently, can be performed for any type of FBM (i.e. it does not have to be a genotype matrix). This is why these two functions are in package {bigstatsr}, and not {bigsnpr}. 4.1 Example Let us reuse the data prepared in 2.3 and the PCs in 3.4. library(bigsnpr) #&gt; Loading required package: bigstatsr obj.bigsnp &lt;- snp_attach(&quot;tmp-data/GWAS_data_sorted_QC.rds&quot;) obj.svd &lt;- readRDS(&quot;tmp-data/PCA_GWAS_data.rds&quot;) PC &lt;- predict(obj.svd) The clinical data includes age, sex, high-density lipoprotein (HDL)-cholesterol (hdl), low-density lipoprotein (LDL)-cholesterol (ldl), triglycerides (tg) and coronary artery disease status (CAD). For the set of covariates, we will use sex, age, and the first 6 PCs: covar &lt;- cbind(as.matrix(obj.bigsnp$fam[c(&quot;sex&quot;, &quot;age&quot;)]), PC[, 1:6]) You probably should not account for other information such as cholesterol as they are heritable covariates (Aschard, Vilhjálmsson, Joshi, Price, &amp; Kraft, 2015; Day, Loh, Scott, Ong, &amp; Perry, 2016). G &lt;- obj.bigsnp$genotypes y &lt;- obj.bigsnp$fam$CAD ind.gwas &lt;- which(!is.na(y) &amp; complete.cases(covar)) To only use a subset of the data stored as an FBM (G here), you should almost never make a copy of the data; instead, use parameters ind.row (or ind.train) and ind.col to apply functions to a subset of the data. Let us perform a case-control GWAS for CAD: gwas &lt;- runonce::save_run( big_univLogReg(G, y[ind.gwas], ind.train = ind.gwas, covar.train = covar[ind.gwas, ], ncores = nb_cores()), file = &quot;tmp-data/GWAS_CAD.rds&quot;) #&gt; user system elapsed #&gt; 0.17 0.14 157.05 #&gt; Code finished running at 2025-06-10 13:44:27 CEST This takes about two minutes with 4 cores on my laptop. Note that big_univLinReg() takes two seconds only, and should give very similar p-values, if you just need something quick. plot(gwas) CHR &lt;- obj.bigsnp$map$chromosome POS &lt;- obj.bigsnp$map$physical.pos snp_manhattan(gwas, CHR, POS, npoints = 50e3) + ggplot2::geom_hline(yintercept = -log10(5e-8), linetype = 2, color = &quot;red&quot;) Here, nothing is genome-wide significant because of the small sample size. y2 &lt;- obj.bigsnp$fam$hdl ind.gwas2 &lt;- which(!is.na(y2) &amp; complete.cases(covar)) gwas2 &lt;- big_univLinReg(G, y2[ind.gwas2], ind.train = ind.gwas2, covar.train = covar[ind.gwas2, ], ncores = nb_cores()) snp_manhattan(gwas2, CHR, POS, npoints = 50e3) + ggplot2::geom_hline(yintercept = -log10(5e-8), linetype = 2, color = &quot;red&quot;) Some other example code: GWAS in iPSYCH; you can perform the GWAS on multiple nodes in parallel that would each process a chunk of the variants only GWAS for very large data and multiple phenotypes; you should perform the GWAS for all phenotypes for a “small” chunk of columns to avoid repeated access from disk, and can process these chunks on multiple nodes in parallel some template for {future.batchtools} when using Slurm References Aschard, H., Vilhjálmsson, B.J., Joshi, A.D., Price, A.L., &amp; Kraft, P. (2015). Adjusting for heritable covariates can bias effect estimates in genome-wide association studies. The American Journal of Human Genetics, 96, 329–339. Day, F.R., Loh, P.-R., Scott, R.A., Ong, K.K., &amp; Perry, J.R. (2016). A robust example of collider bias in a genetic association study. The American Journal of Human Genetics, 98, 392–393. "],["fine-mapping-with-susie.html", "Chapter 5 Fine-mapping with SuSiE 5.1 Objective 5.2 Simulated Example 5.3 Real data", " Chapter 5 Fine-mapping with SuSiE This tutorial was created largely by modifying pre-existing tutorials written by Alesha Hatton (https://cnsgenomics.com/data/teaching/GNGWS23/module1/11_fine-mapping.html) and Gao Wang (https://stephenslab.github.io/susie-paper/manuscript_results/pedagogical_example.html). Thank you Alesha and Gao for your excellent tutorials! 5.1 Objective SuSiE is a fine-mapping method used to determine which variants are most likely to be causal for a trait. It uses a Bayesian iterative approach to create “credible sets” of SNPs that are likely to each contain a causal variant. In this tutorial we will first use SuSiE on simulated data where we know the true causal effects. We will then apply it to real data from (Ruth et al., 2020). 5.1.1 Requirements: 1000 Genomes European reference panel in PLINK1 format (bed/bim/fam) GWAS summary statistics from (Ruth et al., 2020) (GWAS catalog accession: GCST90012102) PLINK 1.9 R packages susieR, dplyr, ggplot2, ggrepel, bigsnpr, and bigreadr. 5.1.2 Load libraries library(susieR) library(dplyr) library(ggplot2) library(ggrepel) library(bigsnpr) library(bigreadr) set.seed(7236) 5.2 Simulated Example This example uses simulated data to illustrate the use of SuSiE for fine-mapping over stage-wise selection. 5.2.1 Load data # This data is included in the susieR package dat &lt;- N2finemapping str(dat) #&gt; List of 8 #&gt; $ X : num [1:574, 1:1002] 0.703 0.703 -0.297 -0.297 0.703 ... #&gt; $ chrom : chr &quot;chr8&quot; #&gt; $ pos : int [1:1002(1d)] 38854423 38854585 38854614 38854829 38855770 38856373 38856591 38856612 38856903 38857229 ... #&gt; $ true_coef : num [1:1002, 1:2] 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ residual_variance: num [1:2(1d)] 1.1 1.01 #&gt; $ Y : num [1:574, 1:2] 1.0446 -1.3656 -0.0235 -0.4344 0.4681 ... #&gt; $ allele_freq : num [1:1002, 1] 0.1483 0.0209 0.1368 0.2134 0.5627 ... #&gt; $ V : num [1:2, 1:2] 1.344 -0.0336 -0.0336 1.2541 #This simulated data-set has two replicates. Let&#39;s focus on the first replicate: y &lt;- dat$Y[, 1] 5.2.2 Fit SuSiE to the data Also perform univariate regression so that PIPs can be compared with p-values # Fit SuSiE with L=5 (maximum number of causal variants per replicate) fitted &lt;- susie(dat$X, y, L = 5, estimate_residual_variance = TRUE, scaled_prior_variance = 0.2, tol = 1e-3, track_fit = TRUE, compute_univariate_zscore = TRUE, coverage = 0.95, min_abs_corr = 0.1) str(fitted, max.level = 1) #&gt; List of 21 #&gt; $ alpha : num [1:5, 1:1002] 9.98e-04 8.96e-32 9.32e-19 9.98e-04 9.98e-04 ... #&gt; $ mu : num [1:5, 1:1002] 0 -0.0221 -0.0514 0 0 ... #&gt; $ mu2 : num [1:5, 1:1002] 0 0.00232 0.00447 0 0 ... #&gt; $ Xr : num [1:574] -0.842 -0.274 -0.842 -0.842 1.209 ... #&gt; $ KL : num [1:5] -1.49e-05 5.87 8.68 -1.49e-05 -1.49e-05 #&gt; $ lbf : num [1:5] 1.49e-05 6.23e+01 3.31e+01 1.49e-05 1.49e-05 #&gt; $ lbf_variable : num [1:5, 1:1002] 0 -2.33 -1.49 0 0 ... #&gt; $ sigma2 : num 1.06 #&gt; $ V : num [1:5] 0 0.251 0.154 0 0 #&gt; $ pi : num [1:1002] 0.000998 0.000998 0.000998 0.000998 0.000998 ... #&gt; $ null_index : num 0 #&gt; $ converged : logi TRUE #&gt; $ elbo : num [1:10] -867 -861 -858 -854 -850 ... #&gt; $ niter : int 10 #&gt; $ intercept : num -7.82e-17 #&gt; $ fitted : num [1:574] -0.842 -0.274 -0.842 -0.842 1.209 ... #&gt; $ trace :List of 10 #&gt; $ sets :List of 5 #&gt; $ pip : num [1:1002] 0 0 0 0 0 0 0 0 0 0 ... #&gt; $ z : num [1:1002] -0.8091 1.1147 -0.5836 -0.0842 -2.1866 ... #&gt; $ X_column_scale_factors: num [1:1002] 0.486 0.2 0.494 0.603 0.708 ... #&gt; - attr(*, &quot;class&quot;)= chr &quot;susie&quot; # Let&#39;s have a look at the first iteration (by setting max_iter=1 this will give us the first iteration of fitted) fitted.one.iter &lt;- susie(dat$X, y, L = 5, max_iter = 1, estimate_residual_variance = TRUE, scaled_prior_variance = 0.2, tol = 1e-3, coverage = 0.95, min_abs_corr = 0.1) #&gt; Warning in susie(dat$X, y, L = 5, max_iter = 1, estimate_residual_variance #&gt; = TRUE, : IBSS algorithm did not converge in 1 iterations! str(fitted.one.iter) #&gt; List of 19 #&gt; $ alpha : num [1:5, 1:1002] 5.22e-18 1.61e-04 6.10e-04 7.44e-04 8.03e-04 ... #&gt; $ mu : num [1:5, 1:1002] -0.03868 -0.02164 -0.01568 -0.01138 -0.00922 ... #&gt; $ mu2 : num [1:5, 1:1002] 0.00381 0.002501 0.001695 0.001228 0.000992 ... #&gt; $ Xr : num [1:574] -0.814 -0.187 -0.802 -0.748 0.675 ... #&gt; $ KL : num [1:5] 6.021 2.322 0.713 0.404 0.295 #&gt; $ lbf : num [1:5] 31.0473 0.9323 0.0954 0.0364 0.0199 #&gt; $ lbf_variable : num [1:5, 1:1002] -1.836 -0.893 -0.396 -0.257 -0.198 ... #&gt; $ sigma2 : num 1.15 #&gt; $ V : num [1:5] 0.17389 0.01527 0.00379 0.00207 0.00148 #&gt; $ pi : num [1:1002] 0.000998 0.000998 0.000998 0.000998 0.000998 ... #&gt; $ null_index : num 0 #&gt; $ elbo : num -867 #&gt; $ niter : int 1 #&gt; $ converged : logi FALSE #&gt; $ intercept : num -3.47e-17 #&gt; $ fitted : num [1:574] -0.814 -0.187 -0.802 -0.748 0.675 ... #&gt; $ sets :List of 5 #&gt; ..$ cs :List of 1 #&gt; .. ..$ L1: int [1:24] 765 767 770 774 776 778 780 782 783 788 ... #&gt; ..$ purity :&#39;data.frame&#39;: 1 obs. of 3 variables: #&gt; .. ..$ min.abs.corr : num 0.78 #&gt; .. ..$ mean.abs.corr : num 0.922 #&gt; .. ..$ median.abs.corr: num 0.92 #&gt; ..$ cs_index : int 1 #&gt; ..$ coverage : num 0.955 #&gt; ..$ requested_coverage: num 0.95 #&gt; $ pip : num [1:1002] 0.00232 0.00219 0.0022 0.0022 0.00315 ... #&gt; $ X_column_scale_factors: num [1:1002] 0.486 0.2 0.494 0.603 0.708 ... #&gt; - attr(*, &quot;class&quot;)= chr &quot;susie&quot; 5.2.3 Plot the SuSiE results Plot both PIPs from SuSiE as well as the p-values from the regressions. b &lt;- dat$true_coef[, 1] b[which(b != 0)] &lt;- 1 # Run this code all at once to get side-by-side plots par_saved &lt;- par(mfrow = c(1, 3), cex.axis = 0.9) # Plot the marginal associations susie_plot(fitted, y = &quot;z&quot;, b = b, max_cs = 1, main = &quot;Marginal associations&quot;, xlab = &quot;variable (SNP)&quot;, col = &quot;#767676&quot;) # Plot PIPs after the first iteration susie_plot(fitted.one.iter, y = &quot;PIP&quot;, b = b, max_cs = 0.4, main = &quot;IBSS after 1 iteration&quot;, add_legend = FALSE, ylim = c(0, 1), xlab = &quot;variable (SNP)&quot;, col = &quot;#767676&quot;) # Plot PIPs after convergence susie_plot(fitted, y = &quot;PIP&quot;, b = b, max_cs = 0.4, main = &quot;IBSS after 10 iterations&quot;, add_legend = FALSE, ylim = c(0, 1), xlab = &quot;variable (SNP)&quot;, col = &quot;#767676&quot;) par(par_saved) The “true” effects are highlighted in red. The strongest signal by p-value does not contain the causal variant, but is being tagged by two causal variants. The first iteration of SuSiE identifies the strongest signal by p-value, but by the 10th iteration the true causal variants are identified within two credible sets. 5.2.4 Let’s take a closer look at which variants are in the credible sets fitted.one.iter$sets$cs #&gt; $L1 #&gt; [1] 765 767 770 774 776 778 780 782 783 788 790 791 792 814 817 824 827 #&gt; [18] 834 837 838 847 849 868 869 fitted$sets$cs #&gt; $L2 #&gt; [1] 850 913 914 915 916 920 924 925 926 927 930 931 933 934 #&gt; [15] 935 942 946 948 951 952 962 967 968 979 980 982 983 985 #&gt; [29] 988 989 993 994 996 999 1000 1001 1002 #&gt; #&gt; $L3 #&gt; [1] 337 379 440 5.2.5 How correlated are the variants in the credible sets? fitted$sets$purity #&gt; min.abs.corr mean.abs.corr median.abs.corr #&gt; L2 0.9722386 0.9938064 0.9947184 #&gt; L3 0.8534981 0.8775989 0.8848378 5.3 Real data In the simulation we used individual level data (genotypes and phenotypes). Often this is not available due to data access restrictions. Here we will use GWAS summary statistics and an LD reference panel. Let’s look at bioavailable testosterone in females from (Ruth et al., 2020). 5.3.1 Import GWAS data First, download the GWAS summary statistics from GWAS catalog. The accession for this study is GCST90012102. ## real data # tgz &lt;- runonce::download_file( # &quot;https://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90012001-GCST90013000/GCST90012102/GCST90012102_buildGRCh37.tsv.gz&quot;, # dir = &quot;tmp-data&quot;) # 419 MB ## small subset, for the tutorial tgz &lt;- runonce::download_file( &quot;https://figshare.com/ndownloader/files/55262768&quot;, dir = &quot;tmp-data&quot;, fname = &quot;FT_sumstats_small.tsv.gz&quot;) readLines(tgz, n = 3) #&gt; [1] &quot;variant_id\\tchromosome\\tbase_pair_location\\teffect_allele\\tother_allele\\teffect_allele_frequency\\timputation_quality\\tbeta\\tstandard_error\\tp_value&quot; #&gt; [2] &quot;rs72858371\\t1\\t6409383\\tT\\tC\\t0.986224\\t0.977552\\t-0.00615364\\t0.0108886\\t0.64&quot; #&gt; [3] &quot;rs72633437\\t1\\t6409494\\tC\\tT\\t0.906138\\t0.988959\\t0.00289667\\t0.00434703\\t0.39&quot; And some reference panel to compute LD from: ## real data # gzip &lt;- runonce::download_file( # &quot;https://vu.data.surfsara.nl/index.php/s/VZNByNwpD8qqINe/download&quot;, # fname = &quot;g1000_eur.zip&quot;, dir = &quot;tmp-data&quot;) # 488 MB ## small subset, for the tutorial gzip &lt;- runonce::download_file( &quot;https://figshare.com/ndownloader/files/55263098&quot;, fname = &quot;g1000_eur_small.zip&quot;, dir = &quot;tmp-data&quot;) unzip(gzip, exdir = &quot;tmp-data&quot;, overwrite = FALSE) g1000_map &lt;- fread2(&quot;tmp-data/g1000_eur_small.bim&quot;, select = c(1:2, 4:6), col.names = c(&quot;chr&quot;, &quot;rsid&quot;, &quot;pos&quot;, &quot;a1&quot;, &quot;a0&quot;)) # import GWAS summary statistics of bioavailable testosterone in females FT &lt;- fread2(tgz) head(FT) #&gt; variant_id chromosome base_pair_location effect_allele other_allele #&gt; 1 rs72858371 1 6409383 T C #&gt; 2 rs72633437 1 6409494 C T #&gt; 3 rs151043271 1 6409495 G A #&gt; 4 rs58484986 1 6409653 C G #&gt; 5 rs60772726 1 6409662 A T #&gt; effect_allele_frequency imputation_quality beta standard_error #&gt; 1 0.986224 0.977552 -0.00615364 0.01088860 #&gt; 2 0.906138 0.988959 0.00289667 0.00434703 #&gt; 3 0.998537 0.732147 -0.02447490 0.03868080 #&gt; 4 0.986228 0.976894 -0.00623617 0.01089580 #&gt; 5 0.986228 0.976844 -0.00625052 0.01089570 #&gt; p_value #&gt; 1 0.64 #&gt; 2 0.39 #&gt; 3 0.40 #&gt; 4 0.63 #&gt; 5 0.63 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 1 rows ] FT_cleaned &lt;- FT %&gt;% # QC on MAF &gt;= 0.01 filter(effect_allele_frequency &gt;= 0.01 &amp; effect_allele_frequency &lt;= 0.99) %&gt;% # rename some columns for compatibility with bigsnpr::snp_match() rename(chr = chromosome, pos = base_pair_location, a1 = effect_allele, a0 = other_allele) %&gt;% # align alleles to reference panel snp_match(g1000_map) # match on chr/pos but can also match on chr/rsid #&gt; 25,328 variants to be matched. #&gt; 3,099 ambiguous SNPs have been removed. #&gt; 18,293 variants have been matched; 0 were flipped and 14,274 were reversed. 5.3.2 Find window around loci of interest Let’s look at two loci: Locus 1: rs1989147. Locus 2: rs34954997, rs11879227, rs34255979. These variants in locus 2 are nearby so will be considered as one locus for the purpose of running SuSiE. ## Locus 1 ## # find coordinates filter(FT_cleaned, rsid == &quot;rs1989147&quot;) # on chr1 #&gt; chr pos a0 a1 variant_id effect_allele_frequency imputation_quality #&gt; 1 1 7909373 C T rs1989147 0.806791 0.97999 #&gt; beta standard_error p_value _NUM_ID_.ss rsid _NUM_ID_ #&gt; 1 -0.0235512 0.00322554 7e-14 5329 rs1989147 12274 # Extract 1 Mb locus surrounding rs1989147 locus1 &lt;- filter(FT_cleaned, chr == 1, pos &gt; 7909373 - 5e5, pos &lt; 7909373 + 5e5) # Plot locus ggplot(locus1, aes(x = pos, y = -log10(p_value))) + geom_point(alpha = 0.8, size = 1.3) + geom_point(aes(x = pos, y = -log10(p_value)), color = &quot;red&quot;, size = 2, data = filter(locus1, rsid == &quot;rs1989147&quot;)) + geom_label_repel(aes(label = ifelse(rsid == &quot;rs1989147&quot;, rsid, NA)), size = 4, min.segment.length = 0) #&gt; Warning: Removed 2815 rows containing missing values or values outside the scale #&gt; range (`geom_label_repel()`). 5.3.3 Create LD matrix As we are using GWAS summary statistics, we need information of the correlation between variants. Here we are using 1000 Genomes European for convenience. If you are performing this analysis yourself, it is advised to use a larger sample. This requires PLINK to be installed and the 1000 Genomes European reference panel to be downloaded. Note we are calculating “r” not “r2”. # Export the SNPs in this locus locus1_snps_txt &lt;- tempfile(fileext = &quot;.txt&quot;) write(locus1$rsid, file = locus1_snps_txt) # Compute correlation matrix (LD) with PLINK plink &lt;- download_plink(&quot;tmp-data&quot;) system(glue::glue( &quot;{plink} --bfile tmp-data/g1000_eur_small&quot;, &quot; --extract {locus1_snps_txt}&quot;, &quot; --keep-allele-order&quot;, &quot; --r square&quot;, # correlations as a square matrix, not squared correlations &quot; --out tmp-data/ld_locus1&quot; )) #&gt; PLINK v1.9.0-b.7.7 64-bit (22 Oct 2024) cog-genomics.org/plink/1.9/ #&gt; (C) 2005-2024 Shaun Purcell, Christopher Chang GNU General Public License v3 #&gt; Logging to tmp-data/ld_locus1.log. #&gt; Options in effect: #&gt; --bfile tmp-data/g1000_eur_small #&gt; --extract C:\\Users\\au639593\\AppData\\Local\\Temp\\Rtmps999SB\\file7dc47c92190f.txt #&gt; --keep-allele-order #&gt; --out tmp-data/ld_locus1 #&gt; --r square #&gt; #&gt; 32574 MB RAM detected; reserving 16287 MB for main workspace. #&gt; 56148 variants loaded from .bim file. #&gt; 503 people (240 males, 263 females) loaded from .fam. #&gt; --extract: 2816 variants remaining. #&gt; Using up to 8 threads (change this with --threads). #&gt; Before main variant filters, 503 founders and 0 nonfounders present. #&gt; Calculating allele frequencies... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\b\b done. #&gt; Total genotyping rate is in [0.9999995, 1). #&gt; 2816 variants and 503 people pass filters and QC. #&gt; Note: No phenotypes present. #&gt; --r square to tmp-data/ld_locus1.ld ... 0% [processing]\b\b\b\b\b\b\b\b\b\b\bwriting] \b\b\b\b\b\b\b\b\b\b\b\b\b \b\b\b\b\b\b\b\b\b\b\b\bdone. # Read in LD matrix ld_mat &lt;- as.matrix(fread2(&quot;tmp-data/ld_locus1.ld&quot;)) 5.3.4 Read in data and fit SuSiE susie_rss() is the function to fit SuSiE using summary statistics. Earlier we used susie() function which requires individual level data. # Fit SuSiE using sample size from publication (n=188507) fitted_rss_1 = susie_rss(bhat = locus1$beta, shat = locus1$standard_error, n = 188507, R = ld_mat) 5.3.5 Examine results # Examine results summary(fitted_rss_1) #&gt; #&gt; Variables in credible sets: #&gt; #&gt; variable variable_prob cs #&gt; 1456 0.09199869 1 #&gt; 1420 0.07451778 1 #&gt; 1417 0.06848847 1 #&gt; 1401 0.06379124 1 #&gt; 1334 0.05783427 1 #&gt; 1364 0.05781606 1 #&gt; 1367 0.05778666 1 #&gt; 1331 0.05777183 1 #&gt; 1347 0.05429258 1 #&gt; 1288 0.05367458 1 #&gt; 1339 0.04928034 1 #&gt; 1280 0.04659030 1 #&gt; 1391 0.04472727 1 #&gt; 1378 0.04098725 1 #&gt; 1256 0.03098191 1 #&gt; 1257 0.03085088 1 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 5 rows ] #&gt; #&gt; Credible sets summary: #&gt; #&gt; cs cs_log10bf cs_avg_r2 cs_min_r2 #&gt; 1 7.455457 0.9186663 0.8268138 #&gt; variable #&gt; 1256,1257,1267,1270,1272,1280,1288,1314,1316,1331,1334,1339,1347,1364,1367,1378,1391,1401,1417,1420,1456 locus1_susie &lt;- arrange(summary(fitted_rss_1)$vars, variable) locus1 &lt;- cbind(locus1, locus1_susie[-1]) # Plot ggplot(locus1, aes(x = pos, y = -log10(p_value))) + geom_point(alpha = 0.8, size = 1.3) + geom_point(color = &quot;red&quot;, size = 2, data = filter(locus1, cs == 1)) + geom_label_repel(aes(label = rsid), size = 2, max.overlaps = 45, data = filter(locus1, cs == 1)) Challenge 1 How does the PIP compare to the p-value? Generate a plot to show this. 5.3.6 Locus 2 locus2 &lt;- filter(FT_cleaned, chr == 19, pos &gt; 45417638 - 5e5, pos &lt; 46384830 + 5e5) Now perform similar analyses on locus2. Challenge 2 How does the PIP compare to the p-value? Generate a plot to show this. Challenge 3 Why might there be no result in fitted_rss_2 for L=2? Challenge 4 What if we changed to a 75% credible set for locus 2? Write code to do this and plot. Can we trust this result? 5.3.7 Reflections What can you do next with these results? What is the advantages of using SuSiE over conditional approaches? What assumptions are we making when using SuSiE? References Ruth, K.S., Day, F.R., Tyrrell, J., Thompson, D.J., Wood, A.R., Mahajan, A., et al. (2020). Using human genetics to understand the disease impacts of testosterone in men and women. Nature Medicine, 26, 252–258. "],["references.html", "References", " References Aschard, H., Vilhjálmsson, B.J., Joshi, A.D., Price, A.L., &amp; Kraft, P. (2015). Adjusting for heritable covariates can bias effect estimates in genome-wide association studies. The American Journal of Human Genetics, 96, 329–339. Bycroft, C., Freeman, C., Petkova, D., Band, G., Elliott, L.T., Sharp, K., et al. (2018). The UK Biobank resource with deep phenotyping and genomic data. Nature, 562, 203–209. Chang, C.C., Chow, C.C., Tellier, L.C., Vattikuti, S., Purcell, S.M., &amp; Lee, J.J. (2015). Second-generation PLINK: Rising to the challenge of larger and richer datasets. Gigascience, 4, s13742–015. Day, F.R., Loh, P.-R., Scott, R.A., Ong, K.K., &amp; Perry, J.R. (2016). A robust example of collider bias in a genetic association study. The American Journal of Human Genetics, 98, 392–393. Manichaikul, A., Mychaleckyj, J.C., Rich, S.S., Daly, K., Sale, M., &amp; Chen, W.-M. (2010). Robust relationship inference in genome-wide association studies. Bioinformatics, 26, 2867–2873. Privé, F. (2022). Using the UK Biobank as a global reference of worldwide populations: application to measuring ancestry diversity from GWAS summary statistics. Bioinformatics, 38, 3477–3480. Privé, F., Aschard, H., Carmi, S., Folkersen, L., Hoggart, C., O’Reilly, P.F., &amp; Vilhjálmsson, B.J. (2022). Portability of 245 polygenic scores when derived from the UK Biobank and applied to 9 ancestry groups from the same cohort. The American Journal of Human Genetics, 109, 12–23. Privé, F., Aschard, H., Ziyatdinov, A., &amp; Blum, M.G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34, 2781–2787. Privé, F., Luu, K., Blum, M.G., McGrath, J.J., &amp; Vilhjálmsson, B.J. (2020). Efficient toolkit implementing best practices for principal component analysis of population genetic data. Bioinformatics, 36, 4449–4457. Privé, F., Luu, K., Vilhjálmsson, B.J., &amp; Blum, M.G. (2020). Performing highly efficient genome scans for local adaptation with R package pcadapt version 4. Molecular Biology and Evolution, 37, 2153–2154. Reed, E., Nunez, S., Kulp, D., Qian, J., Reilly, M.P., &amp; Foulkes, A.S. (2015). A guide to genome-wide association analysis and post-analytic interrogation. Statistics in Medicine, 34, 3769–3792. Ruth, K.S., Day, F.R., Tyrrell, J., Thompson, D.J., Wood, A.R., Mahajan, A., et al. (2020). Using human genetics to understand the disease impacts of testosterone in men and women. Nature Medicine, 26, 252–258. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
