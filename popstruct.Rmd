---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Population structure

```{r setup, include=FALSE}
WORDS_TO_IGNORE <- c("pca", "loadings", "pcadapt", "autoSVD")
source("knitr-options.R")
source("spelling-check.R")
```

## Principal Component Analysis (PCA)

PCA on the genotype matrix can be used to capture population structure.
However, PCA can actually capture different kinds of structure [@prive2020efficient]:

- population structure (what we want),

- Linkage Disequilibrium (LD) structure, when there are too many correlated variants (e.g. within long-range LD regions) and not enough population structure (see [this vignette](https://privefl.github.io/bigsnpr/articles/how-to-PCA.html)),

- relatedness structure, when there are related individuals who usually cluster together in later PCs,

- noise, basically just circles when looking at PC scores.

Capturing population structure with PCA is the second main topic of my research work (after polygenic scores).

- In @prive2017efficient, I introduced an algorithm to compute PCA for a `bigSNP` object while accounting for the LD problem by using clumping (not pruning, cf. [this vignette](https://privefl.github.io/bigsnpr/articles/pruning-vs-clumping.html)) and an *automatic* detection and removal of long-range LD regions.

- In @prive2020performing, I improved the implementation of the pcadapt algorithm, which detects variants associated with population structure (i.e. some kind of GWAS for population structure).

- In @prive2020efficient, I extended bigsnpr to also be able to run PCA on PLINK bed files directly with a small percentage of missing values, and investigated best practices for PCA in more detail.

- In @prive2021high and @prive2021using, I showed how to use PCA for ancestry inference, including grouping individuals in homogeneous ancestry groups, and inferring ancestry proportions from genotype data but also from allele frequencies only (see [this vignette](https://privefl.github.io/bigsnpr/articles/ancestry.html)).


## The problem with LD

Let's reuse the data prepared in \@ref(exo-preprocessing).

```{r, warning=FALSE}
library(ggplot2)
library(bigsnpr)

bigsnp <- snp_attach("tmp-data/GWAS_data_sorted_QC.rds")
G <- bigsnp$genotypes
NCORES <- nb_cores()
```

:::: {.infobox .exo}
Use `big_randomSVD()` to perform a SVD/PCA on `G`. Do not forget to use some scaling (at least some centering). 

Look at PC scores and PC loadings with `plot()`. What do you see for PC4? Color PC scores using the most associated variant with PC4.
::::

<details>
<summary>Click to see solution</summary>

```{r}
svd <- runonce::save_run(
  big_randomSVD(G, fun.scaling = big_scale(), ncores = NCORES),
  file = "tmp-data/svd_with_ld.rds")
plot(svd)
plot(svd, type = "scores")
plot(svd, type = "scores", scores = 3:4)
plot(svd, type = "loadings", loadings = 1:10, coef = 0.4)
```

What is going on with PC4?

```{r}
the_max <- which.max(abs(svd$v[, 4]))
plot(svd, type = "scores", scores = 3:4) +
  aes(color = as.factor(G[, the_max])) + 
  labs(color = "Genotype at most influential SNP") +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  theme(legend.position = "bottom",
        legend.text = element_text(margin = margin(r = 6)))
```

PC4 is basically capturing variation in a block of LD (the peak you see for loadings of PC4) and is then very correlated to genetic variants in this region.

</details>

***

:::: {.infobox .caution}
You really want to avoid using PCs that capture LD e.g. as covariates in GWAS because it will cause some collider bias [@prive2021identifying; @grinde2024adjusting].
::::

To avoid capturing LD in PCA, it has been recommended to perform some pruning (removing variants too correlated with one another) AND remove some known list of long-range LD regions (that can still be captured by PCA, even after a stringent pruning step) [@price2008long; @abdellaoui2013population]. But this is not enough; this is exactly what the UK Biobank did [@bycroft2018uk], and this how the PC loadings of the 40 PCs they provide look like:

```{r, echo=FALSE, out.width="50%"}
knitr::include_graphics("https://github.com/privefl/thesis-docs/blob/master/figures/loadings-ukbb.jpeg?raw=true")
```

**I recommend using only the first 16 PCs provided by the UK Biobank [@prive2020efficient].** If you want to compute PCs yourself, I recommend using the autoSVD functions I developed that perform an *automatic* detection and removal of long-range LD regions.


## Best practices for PCA of genetic data

There can be many steps to properly perform a PCA; you can find more about this in @prive2020efficient.
Let's have a look at [the corresponding tutorial from the bigsnpr website](https://privefl.github.io/bigsnpr/articles/bedpca.html).


## Exercise {#exo-pca}

:::: {.infobox .exo}
Let's reuse the data prepared in \@ref(exo-preprocessing).

Follow the previous tutorial to perform a PCA for this data, using either `snp_*` functions on the bigSNP object or `bed_*` functions on the bed file mapped.
::::

<details>
<summary>Click to see solution</summary>

First, let's get an idea of the relatedness in the data using
```{r, results='hide'}
library(bigsnpr)
(NCORES <- nb_cores())
plink2 <- download_plink2("tmp-data")
rel <- snp_plinkKINGQC(plink2, "tmp-data/GWAS_data_sorted_QC.bed",
                       thr.king = 2^-4.5, make.bed = FALSE, ncores = NCORES)
```

```{r}
hist(log2(rel$KINSHIP), "FD"); abline(v = c(-4.5, -3.5), col = "red")
```

:::: {.infobox .info}
When computing relatedness with KING, LD pruning is *NOT* recommended. However, it may be useful to filter out some variants that are highly associated with population structure, e.g. as performed in the UK Biobank [@bycroft2018uk]. For example, see [this code](https://github.com/privefl/bigsnpr-extdoc/blob/main/example-code/2-rel-and-pca.R).
::::

Relatedness should not be a major issue here. Let's now compute PCs.

:::: {.infobox .info}
All the code that follows could be run on the bigSNP object we made before. Nevertheless, to showcase the `bed_*` functions here, we will run the following analyses on the bed file directly.
::::

```{r}
# Memory-map a bed file directly
obj.bed <- bed("tmp-data/GWAS_data_sorted_QC.bed")
```

```{r}
obj.svd <- runonce::save_run(
  bed_autoSVD(obj.bed, k = 12, ncores = NCORES),
  file = "tmp-data/PCA_GWAS_data.rds")
```

```{r, fig.asp=0.8}
plot(obj.svd)
plot(obj.svd, type = "scores", scores = 1:12, coeff = 0.5)
```

There is some population structure (maybe up to 6 PCs). You should also check loadings to make sure there is no LD structure (peaks on loadings):

```{r}
plot(obj.svd, type = "loadings", loadings = 1:6, coeff = 0.5)
```

No peaks, but loadings of PC4 are a bit odd.

If you expect the individuals to mostly come from one population (e.g. in a national biobank), you can simply use a robust distance to identify a homogeneous subset of individuals, then look at the histogram of log-distances to choose a threshold based on visual inspection (here I would probably choose 4.5).

```{r}
PC <- predict(obj.svd)
ldist <- log(bigutilsr::dist_ogk(PC[, 1:6]))
hist(ldist, "FD"); abline(v = 4.5, col = "red")
```

```{r, message=FALSE}
library(ggplot2)
source("https://raw.githubusercontent.com/privefl/paper4-bedpca/master/code/plot_grid2.R")

plot_grid2(plotlist = lapply(1:4, function(k) {
  k1 <- 2 * k - 1
  k2 <- 2 * k
  qplot(PC[, k1], PC[, k2], color = ldist, size = I(2)) +
    scale_color_viridis_c() +
    theme_bigstatsr(0.6) +
    labs(x = paste0("PC", k1), y = paste0("PC", k2), color = "log-distance") +
    coord_equal()
}), nrow = 2, legend_ratio = 0.2, title_ratio = 0)
```

</details>


## Ancestry inference {#ancestry}

It would be nice if we could get a better sense of the ancestry of these individuals.
To achieve this, we can project this data onto the PCA space of many known population groups defined in @prive2021using (based on the UK Biobank and some individuals from the 1000 Genomes).

```{r}
all_freq <- bigreadr::fread2(
  runonce::download_file(
    "https://figshare.com/ndownloader/files/38019027",  # subset for the tutorial (46 MB)
    # "https://figshare.com/ndownloader/files/31620968",  # for real analyses (849 MB)
    dir = "tmp-data", fname = "ref_freqs.csv.gz"))

projection <- bigreadr::fread2(
  runonce::download_file(
    "https://figshare.com/ndownloader/files/38019024",  # subset for the tutorial (44 MB)
    # "https://figshare.com/ndownloader/files/31620953",  # for real analyses (847 MB)
    dir = "tmp-data", fname = "projection.csv.gz"))

# coefficients to correct for overfitting of PCA
correction <- c(1, 1, 1, 1.008, 1.021, 1.034, 1.052, 1.074, 1.099,
                1.123, 1.15, 1.195, 1.256, 1.321, 1.382, 1.443)
```

```{r}
str(all_freq)    # reference allele frequencies
str(projection)  # PC loadings of the reference data
```

:::: {.infobox .exo}
Match variants between `obj.bed` and `all_freq` using `snp_match()`.

For the variants matched, further remove the variants with more than 5% of missing values.
::::

<details>
<summary>Click to see solution</summary>

```{r, warning=FALSE, message=FALSE}
# match variants between the two datasets
library(dplyr)
matched <- obj.bed$map %>%
  transmute(chr = chromosome, pos = physical.pos, a1 = allele1, a0 = allele2) %>%
  mutate(beta = 1) %>%
  snp_match(all_freq[1:5]) %>%
  print()
```

:::: {.infobox .caution}
Some datasets may have the convention that `a0 = allele1, a1 = allele2`, therefore all effects or allele frequencies are reversed (after matching).
::::

```{r}
# further subsetting on missing values
counts <- bed_counts(obj.bed, ind.col = matched$`_NUM_ID_.ss`, ncores = NCORES)
hist(counts[4, ])
ind <- which((counts[4, ] / nrow(obj.bed)) < 0.05)
matched2 <- matched[ind, ]
```

</details>

***

```{r}
# projection matrix
proj_mat <- as.matrix(projection[matched2$`_NUM_ID_`, -(1:5)])
# reference allele frequencies
ref_mat  <- as.matrix(all_freq  [matched2$`_NUM_ID_`, -(1:5)])
# centers of reference populations in the PCA
all_centers <- crossprod(ref_mat, proj_mat)
```

```{r}
# project individuals (divided by 2 -> as AF) onto the PC space
all_proj <- apply(sweep(proj_mat, 2, correction / 2, '*'), 2, function(x) {
  bed_prodVec(obj.bed, x, ind.col = matched2$`_NUM_ID_.ss`, ncores = NCORES,
              # scaling to get G if beta = 1 and (2 - G) if beta = -1
              center = 1 - matched2$beta, scale = matched2$beta)
})
```

:::: {.infobox .question}
When is it needed to use the `correction`? Why can't we use these provided PC loadings to project the UK Biobank individuals?
::::

***

We can then assign each individual to their closest center:
```{r}
# distance of individuals from each reference population (the center)
all_sq_dist <- apply(all_centers, 1, function(one_center) {
  rowSums(sweep(all_proj, 2, one_center, '-')^2)
})

THR <- 0.002  # you can adjust this threshold
thr_sq_dist <- max(dist(all_centers)^2) * THR / 0.16

# gather some groups
group <- colnames(all_freq)[-(1:5)]
group[group %in% c("Scandinavia", "United Kingdom", "Ireland")]   <- "Europe (North West)"
group[group %in% c("Europe (South East)", "Europe (North East)")] <- "Europe (East)"

# assign to closest cluster, when close enough
cluster <- apply(all_sq_dist, 1, function(sq_dist) {
  ind <- which.min(sq_dist)
  if (sq_dist[ind] < thr_sq_dist) group[ind] else NA
})

table(cluster, exclude = NULL)  # 3 NAs -> almost all assigned
```

```{r}
plot_grid2(plotlist = lapply(1:4, function(k) {
  k1 <- 2 * k - 1
  k2 <- 2 * k
  qplot(PC[, k1], PC[, k2], color = cluster, size = I(2)) +
    theme_bigstatsr(0.6) +
    labs(x = paste0("PC", k1), y = paste0("PC", k2), color = "Assigned group") +
    coord_equal()
}), nrow = 2, legend_ratio = 0.25, title_ratio = 0)
```

These are mostly European individuals.
PC4 is definitively a bit odd.

:::: {.infobox .exo}
Try to find out what's going on with PC4.
::::
