---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Population structure

```{r setup, include=FALSE}
WORDS_TO_IGNORE <- c("pca", "loadings", "pcadapt", "autoSVD", "orthonormal")
source("knitr-options.R")
source("spelling-check.R")
```

## Principal Component Analysis (PCA)

PCA is a matrix factorization method designed to identify orthogonal components that sequentially capture the maximum possible variance in the data. 
It is closely related to Singular Value Decomposition (SVD), in which a data matrix $G$ is approximated as $G \approx U D V^T$, where $U$ and $V$ have orthonormal columns and $D$ is a diagonal matrix of singular values. 
In this formulation, the principal component (PC) scores are given by $U D = G V$, representing the projection of $G$ onto the PCA space, while the columns of $V$ correspond to the PC loadings.

PCA on the genotype matrix can be used to capture population structure.
However, PCA can actually capture different kinds of structure [@prive2020efficient]:

- population structure (what we want), e.g. to use PCs as covariates in GWAS to correct for population structure [@price2006principal],

- Linkage Disequilibrium (LD) structure, when there are too many correlated variants (e.g. within long-range LD regions) and not enough population structure (see [this vignette](https://privefl.github.io/bigsnpr/articles/how-to-PCA.html)),

- relatedness structure, when there are related individuals who usually cluster together in later PCs,

- noise, basically just circles when looking at PC scores.

Capturing population structure with PCA is the second main topic of my research work (after polygenic scores).

- In @prive2017efficient, I introduced an algorithm to compute PCA for a `bigSNP` object while accounting for the LD problem by using clumping (not pruning, cf. [this vignette](https://privefl.github.io/bigsnpr/articles/pruning-vs-clumping.html)) and an *automatic* detection and removal of long-range LD regions.

- In @prive2020performing, I improved the implementation of the pcadapt algorithm, which detects variants associated with population structure (i.e. some kind of GWAS for population structure).

- In @prive2020efficient, I extended bigsnpr to also be able to run PCA on PLINK bed files directly with a small percentage of missing values, and investigated best practices for PCA in more detail.

- In @prive2021high and @prive2021using, I showed how to use PCA for ancestry inference, including grouping individuals in homogeneous ancestry groups, and inferring ancestry proportions from genotype data but also from allele frequencies only (see [this vignette](https://privefl.github.io/bigsnpr/articles/ancestry.html)).


## The problem with LD

Let's reuse the data prepared in \@ref(exo-preprocessing).

```{r, warning=FALSE}
library(ggplot2)
source("https://raw.githubusercontent.com/privefl/paper4-bedpca/master/code/plot_grid2.R")
library(bigsnpr)

bigsnp <- snp_attach("tmp-data/GWAS_data_sorted_QC.rds")
G <- bigsnp$genotypes
NCORES <- nb_cores()
```

:::: {.infobox .exo}
Use `big_randomSVD()` to perform a SVD/PCA on `G`. Do not forget to use some scaling (at least some centering). 

Look at PC scores and PC loadings with `plot()`. What do you see for PC4? Color PC scores using the most associated variant with PC4.
::::

<details>
<summary>Click to see solution</summary>

```{r}
svd <- runonce::save_run(
  big_randomSVD(G, fun.scaling = big_scale(), ncores = NCORES),
  file = "tmp-data/svd_with_ld.rds")
plot(svd)  # scree plot -> singular values
plot(svd, type = "scores")  # individuals in the PCA space
plot(svd, type = "scores", scores = 3:4)
# effects of variants along the genome 
# (x-axis: variant index; y-axis: effect of variant in PC)
plot(svd, type = "loadings", loadings = 1:10, coef = 0.4)
```

What is going on with PC4?

```{r}
the_max <- which.max(abs(svd$v[, 4]))
plot(svd, type = "scores", scores = 3:4) +
  aes(color = as.factor(G[, the_max])) + 
  labs(color = "Genotype at most influential SNP") +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  theme(legend.position = "bottom",
        legend.text = element_text(margin = margin(r = 6)))
```

PC4 is basically capturing variation in a block of LD (the peak you see for loadings of PC4) and is then very correlated to genetic variants in this region (especially `the_max`).

```{r, out.width="60%"}
PC4 <- predict(svd)[, 4]
cor(PC4, G[, the_max])
qplot(PC4, G[, the_max], alpha = I(0.1)) + 
  theme_bw(14) + geom_smooth(method = "lm")
```


</details>

***

:::: {.infobox .caution}
You really want to avoid using PCs that capture LD e.g. as covariates in GWAS because it can cause some collider bias [@prive2021identifying; @grinde2024adjusting].
::::

To avoid capturing LD in PCA, it has been recommended to both perform some pruning (removing variants too correlated with one another) and remove some known list of long-range LD regions (that can still be captured by PCA, even after a stringent pruning step) [@price2008long; @abdellaoui2013population]. But this is not enough; this is exactly what the UK Biobank did [@bycroft2018uk], and this how the PC loadings of the 40 PCs they provide look like:

```{r, echo=FALSE, out.width="50%"}
knitr::include_graphics("https://github.com/privefl/thesis-docs/blob/master/figures/loadings-ukbb.jpeg?raw=true")
```

**Therefore I recommend using only the first 16 PCs provided by the UK Biobank [@prive2020efficient].** If you want to compute PCs yourself, I recommend using the autoSVD functions I developed that perform some pruning followed by an *automatic* detection and removal of long-range LD regions.
In case of the UK Biobank, you would get 16 PCs when recomputing PCs yourself on the full dataset.


## Best practices for PCA of genetic data

There can be many steps to properly perform a PCA; you can find more about this in @prive2020efficient.
Let's have a look at [the corresponding tutorial from the bigsnpr website](https://privefl.github.io/bigsnpr/articles/bedpca.html).


## Exercise {#exo-pca}

:::: {.infobox .exo}
Let's reuse the data prepared in \@ref(exo-preprocessing).

Follow the previous tutorial to perform a PCA for this data, using either `snp_*` functions on the bigSNP object or `bed_*` functions on the bed file mapped.
::::

<details>
<summary>Click to see solution</summary>

First, let's get an idea of the relatedness in the data using
```{r, results='hide'}
library(bigsnpr)
(NCORES <- nb_cores())
plink2 <- download_plink2("tmp-data")
rel <- snp_plinkKINGQC(plink2, "tmp-data/GWAS_data_sorted_QC.bed",
                       thr.king = 2^-4.5, make.bed = FALSE, ncores = NCORES)
```

```{r}
hist(log2(rel$KINSHIP), "FD"); abline(v = c(-4.5, -3.5), col = "red")
```

:::: {.infobox .info}
When computing relatedness with KING, LD pruning is *NOT* recommended. However, it may be useful to filter out some variants that are highly associated with population structure, e.g. as performed in the UK Biobank [@bycroft2018uk]. For example, see [this code](https://github.com/privefl/bigsnpr-extdoc/blob/main/example-code/2-rel-and-pca.R).
::::

Relatedness should not be a major issue here. Let's now compute PCs.

:::: {.infobox .info}
All the code that follows could be run on the bigSNP object we made before. Nevertheless, to showcase the `bed_*` functions here, we will run the following analyses on the bed file directly.
::::

```{r}
# Memory-map a bed file directly
obj.bed <- bed("tmp-data/GWAS_data_sorted_QC.bed")
```

```{r}
obj.svd <- runonce::save_run(
  bed_autoSVD(obj.bed, k = 12, ncores = NCORES),
  file = "tmp-data/PCA_GWAS_data.rds")
```

```{r, fig.asp=0.8}
plot(obj.svd)
plot(obj.svd, type = "scores", scores = 1:12, coeff = 0.5)
```

There is some population structure (maybe up to 6 PCs). You should also check loadings to make sure there is no LD structure (peaks on loadings):

```{r}
plot(obj.svd, type = "loadings", loadings = 1:6, coeff = 0.5)
```

No peaks, but loadings of PC4 are a bit odd.

:::: {.infobox .question}
Why do I use hex bins to plot PC loadings?
::::

If you expect the individuals to mostly come from one population (e.g. in a national biobank), you can simply use a robust distance to identify a homogeneous subset of individuals, then look at the histogram of log-distances to choose a threshold based on visual inspection (here I would probably choose 4.5).

```{r}
PC <- predict(obj.svd)
ldist <- log(bigutilsr::dist_ogk(PC[, 1:6]))
hist(ldist, "FD"); abline(v = 4.5, col = "red")
```

```{r}
plot_grid2(plotlist = lapply(1:4, function(k) {
  k1 <- 2 * k - 1
  k2 <- 2 * k
  qplot(PC[, k1], PC[, k2], color = ldist, size = I(2)) +
    scale_color_viridis_c() +
    theme_bigstatsr(0.6) +
    labs(x = paste0("PC", k1), y = paste0("PC", k2), color = "log-distance") +
    coord_equal()
}), nrow = 2, legend_ratio = 0.2, title_ratio = 0)
```

</details>


## Ancestry inference {#ancestry}

It would be useful to get an idea of the ancestry composition of these individuals.
To achieve this, we can project this data onto the PCA space of many known population groups defined in @prive2021using (based on the UK Biobank and some individuals from the 1000 Genomes).

```{r}
all_freq <- bigreadr::fread2(
  runonce::download_file(
    "https://figshare.com/ndownloader/files/38019027",  # subset for the tutorial (46 MB)
    # "https://figshare.com/ndownloader/files/31620968",  # for real analyses (849 MB)
    dir = "tmp-data", fname = "ref_freqs.csv.gz"))

projection <- bigreadr::fread2(
  runonce::download_file(
    "https://figshare.com/ndownloader/files/38019024",  # subset for the tutorial (44 MB)
    # "https://figshare.com/ndownloader/files/31620953",  # for real analyses (847 MB)
    dir = "tmp-data", fname = "projection.csv.gz"))

# coefficients to correct for overfitting of PCA
correction <- c(1, 1, 1, 1.008, 1.021, 1.034, 1.052, 1.074, 1.099,
                1.123, 1.15, 1.195, 1.256, 1.321, 1.382, 1.443)
```

```{r}
str(all_freq)    # reference allele frequencies
str(projection)  # PC loadings of the reference data
```

:::: {.infobox .exo}
Match variants between `obj.bed` and `all_freq` using `snp_match()`. Use `a1 = allele1, a0 = allele2`. You also need to add a column `beta` with 1s, which will tell you whether the alleles have been reversed for matching.

For the variants matched, further remove the variants with more than 5% of missing values.
::::

<details>
<summary>Click to see solution</summary>

```{r, warning=FALSE, message=FALSE}
# match variants between the two datasets
library(dplyr)
matched <- obj.bed$map %>%
  transmute(chr = chromosome, pos = physical.pos, a1 = allele1, a0 = allele2) %>%
  mutate(beta = 1) %>%
  snp_match(all_freq[1:5]) %>%
  print()
```

:::: {.infobox .caution}
Usually `allele1` are the effect alleles.
But some datasets may have the convention that `a0 = allele1, a1 = allele2`, therefore all effects and allele frequencies are reversed (after matching).
::::

```{r}
# further subsetting on missing values
counts <- bed_counts(obj.bed, ind.col = matched$`_NUM_ID_.ss`, ncores = NCORES)
hist(counts[4, ])
ind <- which((counts[4, ] / nrow(obj.bed)) < 0.05)
matched2 <- matched[ind, ]
```

</details>

***

```{r}
# projection matrix
proj_mat <- as.matrix(projection[matched2$`_NUM_ID_`, -(1:5)])
# reference allele frequencies
ref_mat  <- as.matrix(all_freq  [matched2$`_NUM_ID_`, -(1:5)])
# centers of reference populations in the PCA
all_centers <- crossprod(ref_mat, proj_mat)
```

```{r}
# project individuals (divided by 2 -> as AF) onto the PC space
all_proj <- apply(sweep(proj_mat, 2, correction / 2, '*'), 2, function(x) {
  bed_prodVec(obj.bed, x, ind.col = matched2$`_NUM_ID_.ss`, ncores = NCORES,
              # scaling to get G if beta = 1 and (2 - G) if beta = -1
              center = 1 - matched2$beta, scale = matched2$beta)
})
```

:::: {.infobox .info}
The `correction` factors are needed when projecting *new individuals* onto a PCA space to correct for the shrinkage that happens due to "overfitting" of the PCA. This happens particularly when the number of individuals used to derive the PCA is smaller than the number of variables. The amount of correction needed increases for later PCs. You can have a look at @prive2020efficient to read more about this.

Note that the provided `correction` is specific to the PC loadings I provide, so that you don't need to recompute it. It is based on the ratio between the projections using a method that corrects for this shrinkage and the simple projections (simply multiplying by the loadings on the right).
::::

:::: {.infobox .question}
Why can't we use these provided PC loadings and correction factors to project UK Biobank individuals?
::::

***

:::: {.infobox .info}
In @prive2021high, I have showed that distances in the PCA space are approximately proportional to $F_{ST}$ (a genetic distance). So I recommend using distances in the PCA space to assign individuals to clusters. So that clusters remain somewhat homogeneous, a maximum distance can be set based on proportionality with a chosen $F_{ST}$ threshold. 
::::

:::: {.infobox .exo}
For all individuals, compute the squared distances from all centers in the PCA space.

Then, assign each individual to the closest `group`, if close enough (using `thr_sq_dist`).
::::

```{r}
thr_fst <- 0.002  # you can adjust this threshold
thr_sq_dist <- max(dist(all_centers)^2) * thr_fst / 0.16

# combine some close groups
group <- colnames(all_freq)[-(1:5)]
group[group %in% c("Scandinavia", "United Kingdom", "Ireland")]   <- "Europe (North West)"
group[group %in% c("Europe (South East)", "Europe (North East)")] <- "Europe (East)"
```

<details>
<summary>Click to see solution</summary>

We can then assign each individual to their closest center:
```{r}
# distance of individuals from each reference population (the center)
all_sq_dist <- apply(all_centers, 1, function(one_center) {
  rowSums(sweep(all_proj, 2, one_center, '-')^2)
})

# assign to closest cluster, when close enough
cluster <- apply(all_sq_dist, 1, function(sq_dist) {
  ind <- which.min(sq_dist)
  if (sq_dist[ind] < thr_sq_dist) group[ind] else NA
})
```

</details>

```{r}
table(cluster, exclude = NULL)  # 3 NAs -> almost all assigned
```

```{r}
plot_grid2(plotlist = lapply(1:4, function(k) {
  k1 <- 2 * k - 1
  k2 <- 2 * k
  qplot(PC[, k1], PC[, k2], color = cluster, size = I(2)) +
    theme_bigstatsr(0.6) +
    labs(x = paste0("PC", k1), y = paste0("PC", k2), color = "Assigned group") +
    coord_equal()
}), nrow = 2, legend_ratio = 0.25, title_ratio = 0)
```

These are mostly European individuals.
PC4 is definitively a bit odd.

:::: {.infobox .exo}
Try to find out what's going on with PC4.
::::
