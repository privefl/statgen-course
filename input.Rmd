---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Inputs and formats

```{r setup, include=FALSE}
WORDS_TO_IGNORE <- c("nd", "epigenetic", "omics", "reimplementing", "transcriptomic", "bgen", "bgi", "Rcpp")
source("knitr-options.R")
source("spelling-check.R")
rm(X); gc(); file.remove(c("tmp-data/test.bk", "tmp-data/test.rds"))
```

Genetic data is represented as sequences of pairs of alleles (one from both parents). In the following figure, the reference alleles are shown in black, and the alternative alleles—arising from mutations—are shown in blue. 
Here, three DNA positions show alternative alleles; these are called genetic variants. And we refer to them as common variants because the alternative allele is frequent enough in the population.
We can encode this data into a numeric genotype matrix G by counting the number of alternative alleles per individual at each variant.

```{r, echo=FALSE, out.width="65%"}
knitr::include_graphics("images/overview_geneticvariants.png")
```

## Formats of genetic data

There exist many different data formats for genetic data:

- *bed*/*bim*/*fam* files (also called PLINK1 files) that respectively store genotype calls only (0, 1, 2, or NA) in a very condensed way (binary using one byte only for 4 genotypes), information on the genetic variants (text), and information on the individuals (text). PLINK 1.9 and 2.0 [@chang2015second] provide many functions to work with this format.

:::: {.infobox .caution}
The *bed* format presented here is not the same as [the *BED* format](https://en.wikipedia.org/wiki/BED_(file_format)) (a text file format used to store genomic regions as coordinates and associated annotations).
::::

- *bgen* files (usually one per chromosome) that can store imputed probabilities (P(0), P(1), P(2)) that are often transformed to dosage information (expected values: P(1) + 2 P(2)). Each variant is stored compressed, which is very efficient, especially for low-frequency variants. They are accompanied by *bgen.bgi* files that store information on the genetic variants and the position of their corresponding data in the *bgen* files, and by a *sample* file that stores information on the individual IDs. This is the format used for the original UK Biobank imputed data [@bycroft2018uk].

- *pgen*/*pvar*/*psam* files (also called PLINK2 files) that can store imputed data as well, and *pgen* files seem more compressed than *bgen* files. PLINK2 provides many functions to work with this format.

- Many other formats that you can usually convert from using PLINK.


## Main motivation for developing R packages bigstatsr and bigsnpr

At the time, there was a notable lack of user-friendly and efficient R packages for genetic analyses, which posed challenges for researchers. 
The existing workflows often required the use of disparate software tools with inconsistent input formats, reliance on text files for parameter settings, and limited compatibility with exploratory data analysis and familiar R packages. 
Additionally, the development of new methods was hindered by the absence of tools supporting a simple matrix-like data structure. 
To address these challenges, I initiated the development of the R package bigsnpr in 2016, reimplementing the statistical methods commonly used in genetic analyses within a cohesive and accessible R framework.

At some point, I realized that many functions (e.g. to perform genome-wide association studies (GWAS), principal component analysis (PCA), summary statistics, etc.) were not specific to genotype data. Indeed, both association studies and PCA are applicable to other omics data, such as transcriptomic or epigenetic datasets. Therefore I decided to move all these functions that could be used on any data stored as a matrix into a new R package, bigstatsr. This is why there are two packages, where bigstatsr can basically be used by any field using data stored as large numeric matrices, while bigsnpr provides some tools more specific to genotype data, largely building on top of bigstatsr. The initial description of the two packages is available in @prive2017efficient.


## The bigSNP format from bigsnpr

My R package bigsnpr [@prive2017efficient] uses a class called `bigSNP` for representing SNP data. A `bigSNP` object is merely a list with the three following elements:

- `$genotypes`: A [`FBM.code256`](https://privefl.github.io/bigstatsr/reference/FBM.code256-class.html). Rows are samples and columns are genetic variants. This stores genotype calls or *dosages* (rounded to 2 decimal places). More about this format below.
- `$fam`: A `data.frame` with some information on the samples.
- `$map`: A `data.frame` with some information on the genetic variants. 

Package bigsnpr also provides functions for directly working on bed files with a small percentage of missing values [@prive2020efficient].


## Getting a bigSNP object {#getting-bigsnp}

- To read a bigSNP object from *bed*/*bim*/*fam* files, you can use functions `snp_readBed()` and `snp_readBed2()` (the second can read a subset of individuals/variants and use parallelism).

- To read dosages from *BGEN* files, you can use function `snp_readBGEN()`. This function takes around 40 minutes to read 1M variants for 400K individuals using 15 cores. Note that this function currently works only for BGEN v1.2 with probabilities stored as 8 bits (cf. [this issue](https://github.com/privefl/bigsnpr/issues/141#issuecomment-691285671)), which is the case for e.g. the UK Biobank files.

- The previous functions create two new files: `<backingfile>.bk` (binary file that stores the content of the genetic matrix) and `<backingfile>.rds` (stores the R bigSNP object, including some information on how to link with the *bk* file).

- To read any format used in genetics, you can always convert blocks of the data to text files using PLINK, read these using `bigreadr::fread2()`, and fill part of the resulting FBM. For example, see [the code I used to convert the iPSYCH imputed data from the RICOPILI pipeline to my bigSNP format](https://github.com/privefl/bigsnpr-extdoc/blob/main/example-code/1-ricopili-to-bigsnp.R).

**Example converting a bed file to bigSNP:**

```{r}
library(bigsnpr)
bedfile <- system.file("extdata", "example.bed", package = "bigsnpr")
```

:::: {.infobox .exo}
Before using some functions you don't know, have a look at their documentation to see how to use them and some examples (`?snp_readBed`).

Use `snp_readBed()` to transform this data into a bigSNP object.
What do you get? Use `snp_attach()` to get the data into R and explore it a bit.
::::

<details>
<summary>Click to see solution</summary>
```{r}
(rds <- snp_readBed2(bedfile, backingfile = tempfile()))  # get path to new file
bigsnp <- snp_attach(rds)  # can then read in the bigSNP object in any R session
(G <- bigsnp$genotypes)
G[1:5, 1:8]  # first 8 genotypes for first 5 individuals
str(bigsnp$fam)
str(bigsnp$map)
```
</details>

***

**Example directly mapping the bed file:**

:::: {.infobox .exo}
Map the bed file directly using `bed()`. Can you access the same data as with the bigSNP object?
::::

<details>
<summary>Click to see solution</summary>
```{r}
obj.bed <- bed(bedfile)
obj.bed[1:5, 1:8]  # first 8 genotypes for first 5 individuals
str(obj.bed$fam)
str(obj.bed$map)
```
</details>

***

**Example converting a bgen file to bigSNP:**

```{r}
bgen <- runonce::download_file(
  "https://enkre.net/cgi-bin/code/bgen/raw/3ec770a829a753282b5cb45afc3f4eda036b246705b76f9037b6cc98c41a4194?at=example.8bits.bgen",
  fname = "example.bgen")
bgi <- runonce::download_file(
  "https://enkre.net/cgi-bin/code/bgen/raw/dc7276e0f0e2e096f58d2dac645aa5711de2cd64c3b29a07a80575e175344f78?at=example.8bits.bgen.bgi",
  fname = "example.bgen.bgi")
```

:::: {.infobox .exo}
First, use `snp_readBGI()` to get information on the variants.

Then read the first 10 variants using `snp_readBGEN()` (pay attention to the specific format of `list_snp_id`), and `snp_attach()`. 

What extra information about the variants do you get in the bigSNP object?
::::

<details>
<summary>Click to see solution</summary>

```{r}
(var_info <- snp_readBGI(bgi))
(snp_id <- with(var_info[1:10, ], paste(chromosome, position, allele1, allele2, sep = "_")))
(rds <- snp_readBGEN(bgen, backingfile = tempfile(), list_snp_id = list(snp_id)))
bigsnp <- snp_attach(rds)
(G <- bigsnp$genotypes)
str(bigsnp$map)  # `$freq` and `$info` are computed when reading the data
```

</details>

<br>

:::: {.infobox .caution}
There is no `$fam` information when reading BGEN files, which should be read from other data and matched/joined using IDs from the *sample* file. From the BGEN, you can also use these IDs to read a subset of individuals only, as done [in this code](https://github.com/privefl/paper-misspec/blob/main/code/prepare-genotypes.R#L33-L34).
::::

```{r}
sample <- runonce::download_file(
  "https://enkre.net/cgi-bin/code/bgen/raw/a3c4d8e4c132048a502dc00a3e51362f98eda5a2889df695ba260dc48c327fd9?at=example.sample",
  fname = "example.sample")
readLines(sample, n = 6)
```

:::: {.infobox .caution}
What should you be careful about when reading the *sample* file?
::::


## The FBM format from bigstatsr

The format provided in R package bigstatsr is called a Filebacked Big Matrix (FBM). It is an on-disk matrix format that is accessed through memory-mapping.

```{r, echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/privefl/R-presentation/master/memory-solution.svg")
```

How memory-mapping works:

- when you access the 1st element (1st row, 1st col), it accesses a block (say the first column) from disk into memory (RAM)
- when you access the 2nd element (2nd row, 1st col), it is already in memory so it is accessed very fast
- when you access the second column, you access from disk again (once)
- you can access many columns like that, until you do not have enough memory anymore
- some space is freed automatically so that new columns can be accessed into memory
- everything is seamlessly managed by the operating system (OS)
- it is also very convenient for parallelism as data is shared between processes

All the elements of an FBM have the same type; supported types are:

 - `"double"` (the default, double precision -- 8 bytes per element)
 - `"float"` (single precision -- 4 bytes)
 - `"integer"` (signed, so between $\text{-}2^{31}$ and ($2^{31} \text{ - } 1$) -- 4 bytes)
 - `"unsigned short"`: can store integer values from $0$ to $65535$ (2 bytes)
 - `"raw"` or `"unsigned char"`: can store integer values from $0$ to $255$ (1 byte). **It is the basis for class *FBM.code256* that can access 256 arbitrary different numeric values (decoded using a `CODE_*`), which is used in bigsnpr.**
 
The code used in class *FBM.code256* for imputed data is e.g. 
```{r, R.options=list(max.print=1000)}
bigsnpr::CODE_DOSAGE
```
where the first four elements are used to store genotype calls, the next three to store imputed allele counts, and the next 201 values to store dosages rounded to 2 decimal places. This allows for handling many data types (genotype calls and dosages) while storing each element using one byte only (x4 compared to bed files, but /8 compared to double-precision floating-point numbers).


## Working with an FBM

### Similar accessor as R matrices

```{r}
library(bigstatsr)
X <- FBM(2, 5, init = 1:10, backingfile = "tmp-data/test")$save()
```

```{r}
X$backingfile  # the file where numeric data is stored
X$rds  # the file where information about the data is stored
X <- big_attach("tmp-data/test.rds")  # can get the FBM from any R session
```

You can access the whole FBM as an R matrix in memory using `X[]`.
However, if the matrix is too large to fit in memory, you should always access only a subset of columns.
Note that the elements of an FBM are stored column-wise (as for a standard R matrix). Therefore, be careful not to access a subset of rows, since it would read non-contiguous elements from the whole matrix from disk.

```{r}
X[, 1]  # ok (must read first column only)
X[1, ]  # bad (must read all data from disk)
X[]     # super bad (standard R matrix in memory)
```


### Split-(par)Apply-Combine Strategy

```{r}
colSums(X[])  # super bad
```

Instead, the split-apply-combine strategy works well for applying standard R functions to FBMs (possibly in parallel), as implemented in `big_apply()`.

```{r, out.width='90%', echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/privefl/R-presentation/master/split-apply-combine.svg")
```

Learn more with [this tutorial on `big_apply()`](https://privefl.github.io/bigstatsr/articles/big-apply.html).

:::: {.infobox .exo}
Compute the sum of each column of `X <- big_attachExtdata()` using `big_apply()`.
::::


### Similar accessor as Rcpp matrices

In case you want to develop new R functions for the FBM format while coding in C++ (which is the case for many bigstatsr/bigsnpr functions). Note that it is easy to use only a subset of the data without having to change anything in the code.

```{Rcpp, eval=FALSE}
// [[Rcpp::plugins(cpp11)]]
// [[Rcpp::depends(bigstatsr, rmio)]]
#include <bigstatsr/BMCodeAcc.h>

// [[Rcpp::export]]
NumericVector bigcolsums(Environment BM,
                         const IntegerVector& rowInd,
                         const IntegerVector& colInd) {
  
  // the external pointer
  XPtr<FBM> xpBM = BM["address"];
  // accessor to a sub-view of the data + automatically decoded
  SubBMCode256Acc(xpBM, rowInd, colInd, BM["code256"], 1)
  
  size_t n = macc.nrow();          // similar code as for an Rcpp::NumericMatrix
  size_t m = macc.ncol();          // similar code as for an Rcpp::NumericMatrix
  
  NumericVector res(m);
  
  for (size_t j = 0; j < m; j++) 
    for (size_t i = 0; i < n; i++)
      res[j] += macc(i, j);        // similar code as for an Rcpp::NumericMatrix
  
  return res;
}
```

### Some summary functions are already implemented

```{r, R.options=list(max.print=20)}
(X2 <- snp_attachExtdata()$genotypes)
big_colstats(X2)      # sum and var (for each column)
big_scale()(X2)       # mean and sd (for each column)
snp_scaleBinom()(X2)  # 2 * af (mean) and sqrt(2 * af * (1 - af)) (~sd)
```

:::: {.infobox .info}
Functions starting with `big_` are part of bigstatsr and work for any type of FBM, while functions starting with `snp_` or `bed_` are part of bigsnpr and are more specific to genetic data.

There are now many functions implemented in the packages. You can find a comprehensive list of available functions on the package website [of bigstatsr](https://privefl.github.io/bigstatsr/reference/index.html) and [of bigsnpr](https://privefl.github.io/bigsnpr/reference/index.html).
::::

:::: {.infobox .exo}
Take some time to have a look at the different functions available in both bigstatsr and bigsnpr.
::::

:::: {.infobox .question}
What is the difference between functions starting with `snp_` vs `bed_`?
::::

:::: {.infobox .caution}
To only use a subset of the data stored as an FBM, you should almost never make a copy of the data. Instead, to apply functions to a subset of the data, use their parameters `ind.row` (or `ind.train`) and `ind.col`.
::::

```{r, include=FALSE}
rm(X); gc(); file.remove(c("tmp-data/test.bk", "tmp-data/test.rds"))
```

## Exercise

```{r, warning=FALSE}
zip <- runonce::download_file(
  "https://figshare.com/ndownloader/files/38019072",
  dir = "tmp-data", fname = "GWAS_data.zip")
unzip(zip, exdir = "tmp-data", overwrite = FALSE)
bedfile <- "tmp-data/GWAS_data.bed"
```

:::: {.infobox .exo}
Map this data with `bed()` and start exploring it a bit, e.g. what summaries you could compute, what functions you could use.
::::
