---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Inputs and formats

```{r setup, include=FALSE}
WORDS_TO_IGNORE <- c("nd", "bgen", "bgi", "pgen", "Rcpp")
source("knitr-options.R")
source("spelling-check.R")
rm(X); gc(); file.remove(c("tmp-data/test.bk", "tmp-data/test.rds"))
```

## Formats of genetic data

There exist many different data formats for genetic data:

- *bed*/*bim*/*fam* files (also called PLINK1 files) that respectively store genotype calls only (0, 1, 2, or NA) in a very condensed way (one byte only for 4 genotypes), information on the genetic variants, and information on the individuals. PLINK 1.9 and 2.0 provide many functions to work with this format.

- *bgen* files (usually one per chromosome) that can store imputed probabilities (P(0), P(1), P(2)) that are often transformed to dosage information (expected values: P(1) + 2 P(2)). Each variant is stored compressed, which is very efficient, especially for low-frequency variants. They are accompanied by *bgen.bgi* files that store information on the genetic variants and the position of their corresponding data in the *bgen* files, and by a *sample* file that stores information on the individual IDs.

- *pgen* files (also called PLINK2 files) that can store imputed data as well, and seem a bit more compressed than *bgen* files. PLINK2 provides many functions to work with this format.

- Many other formats that you can usually convert from using PLINK.


## The bigSNP format from {bigsnpr}

Package {bigsnpr} [@prive2017efficient] uses a class called `bigSNP` for representing SNP data. A `bigSNP` object is merely a list with the three following elements:

- `$genotypes`: A [`FBM.code256`](https://privefl.github.io/bigstatsr/reference/FBM.code256-class.html). Rows are samples and columns are genetic variants. This stores genotype calls or *dosages* (rounded to 2 decimal places). More about this format below.
- `$fam`: A `data.frame` with some information on the samples.
- `$map`: A `data.frame` with some information on the genetic variants.

The code used in class *FBM.code256* for imputed data is e.g. 
```{r, R.options=list(max.print=1000)}
bigsnpr::CODE_DOSAGE
```
where the first four elements are used to store genotype calls, the next three to store imputed allele counts, and the next 201 values to store dosages rounded to 2 decimal places. This allows for handling many data types (genotype calls and dosages) while storing each element using one byte only (x4 compared to bed files, but /8 compared to double-precision floating-point numbers). 

Package {bigsnpr} also provides functions for directly working on bed files with a small percentage of missing values [@prive2020efficient].


## Getting a bigSNP object {#getting-bigsnp}

- To read a bigSNP object from *bed*/*bim*/*fam* files, you can use functions `snp_readBed()` and `snp_readBed2()` (the second can read a subset of individuals/variants and use parallelism).

- To read dosages from *BGEN* files, you can use function `snp_readBGEN()`. This function takes around 40 minutes to read 1M variants for 400K individuals using 15 cores. Note that this function currently works only for BGEN v1.2 with probabilities stored as 8 bits (cf. [this issue](https://github.com/privefl/bigsnpr/issues/141#issuecomment-691285671)), which is the case for e.g. the UK Biobank files.

- To read any format used in genetics, you can always convert blocks of the data to text files using PLINK, read these using `bigreadr::fread2()`, and fill part of the resulting FBM. For example, see [the code I used to convert the iPSYCH imputed data from the RICOPILI pipeline to my bigSNP format](https://github.com/privefl/bigsnpr-extdoc/blob/main/example-code/1-ricopili-to-bigsnp.R).

**Example converting a bed file to bigSNP:**

```{r}
library(bigsnpr)
bedfile <- system.file("extdata", "example.bed", package = "bigsnpr")
(rds <- snp_readBed2(bedfile, backingfile = tempfile()))  # get path to new file
bigsnp <- snp_attach(rds)  # can then read in the bigSNP object in any R session
(G <- bigsnp$genotypes)
G[1:5, 1:5]
str(bigsnp$fam)
str(bigsnp$map)
```

**Example directly mapping the bed file:**

```{r}
obj.bed <- bed(bedfile)
obj.bed[1:5, 1:5]
str(obj.bed$fam)
str(obj.bed$map)
```

**Example converting a bgen file to bigSNP:**

```{r}
bgen <- runonce::download_file(
  "https://enkre.net/cgi-bin/code/bgen/raw/3ec770a829a753282b5cb45afc3f4eda036b246705b76f9037b6cc98c41a4194?at=example.8bits.bgen",
  fname = "example.bgen")
bgi <- runonce::download_file(
  "https://enkre.net/cgi-bin/code/bgen/raw/dc7276e0f0e2e096f58d2dac645aa5711de2cd64c3b29a07a80575e175344f78?at=example.8bits.bgen.bgi",
  fname = "example.bgen.bgi")
sample <- runonce::download_file(
  "https://enkre.net/cgi-bin/code/bgen/raw/a3c4d8e4c132048a502dc00a3e51362f98eda5a2889df695ba260dc48c327fd9?at=example.sample",
  fname = "example.sample")
```

```{r}
# What should you be careful about when reading this file?
readLines(sample, n = 5)
```

```{r}
library(bigsnpr)
(var_info <- snp_readBGI(bgi))
(snp_id <- with(var_info[1:10, ], paste(chromosome, position, allele1, allele2, sep = "_")))
(rds <- snp_readBGEN(bgen, backingfile = tempfile(), list_snp_id = list(snp_id)))
bigsnp <- snp_attach(rds)
(G <- bigsnp$genotypes)
str(bigsnp$map)  # `$freq` and `$info` are computed when reading the data
```

There is no `$fam` information in this case, which should be read from other data and match using IDs from the *sample* file.


## The FBM format from {bigstatsr}

The format provided in package {bigstatsr} is called a Filebacked Big Matrix (FBM). It is an on-disk matrix format that is accessed through memory-mapping.

```{r, echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/privefl/R-presentation/master/memory-solution.svg")
```

How memory-mapping works:

- when you access the 1st element (1st row, 1st col), it accesses a block (say the first column) from disk into memory (RAM)
- when you access the 2nd element (2nd row, 1st col), it is already in memory so it is accessed very fast
- when you access the second column, you access from disk again (once)
- you can access many columns like that, until you do not have enough memory anymore
- some space is freed automatically so that new columns can be accessed into memory
- everything is seamlessly managed by the operating system (OS)
- it is also very convenient for parallelism as data is shared between processes

All the elements of an FBM have the same type; supported types are:

 - `"double"` (the default, double precision -- 8 bytes per element)
 - `"float"` (single precision -- 4 bytes)
 - `"integer"` (signed, so between $\text{-}2^{31}$ and ($2^{31} \text{ - } 1$) -- 4 bytes)
 - `"unsigned short"`: can store integer values from $0$ to $65535$ (2 bytes)
 - `"raw"` or `"unsigned char"`: can store integer values from $0$ to $255$ (1 byte). **It is the basis for class *FBM.code256* that can access 256 arbitrary different numeric values (decoded using a `CODE_*`), which is used in package {bigsnpr} (see above).**


## Working with an FBM

### Similar accessor as R matrices

```{r}
library(bigstatsr)
X <- FBM(2, 5, init = 1:10, backingfile = "tmp-data/test")$save()
```

```{r}
X$backingfile  # the file where numeric data is stored
X$rds  # the file where information about the data is stored
X <- big_attach("tmp-data/test.rds")  # can get the FBM from any R session
```

You can access the whole FBM as an R matrix in memory using `X[]`.
However, if the matrix is too large to fit in memory, you should always access only a subset of columns.
Note that the elements of the FBM are stored column-wise (as for a standard R matrix). Therefore, be careful not to access a subset of rows, since it would read non-contiguous elements from the whole matrix from disk.

```{r}
X[, 1]  # ok (must read first column only)
X[1, ]  # bad (must read all data from disk)
X[]     # super bad (standard R matrix in memory)
```


### Split-(par)Apply-Combine Strategy

```{r}
colSums(X[])  # super bad
```

Instead, the split-apply-combine strategy works well for applying standard R functions to FBMs (possibly in parallel), as implemented in `big_apply()`.

```{r, out.width='90%', echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/privefl/R-presentation/master/split-apply-combine.svg")
```

Learn more with [this tutorial on `big_apply()`](https://privefl.github.io/bigstatsr/articles/big-apply.html).

:::: {.infobox .exo}
Compute the sum of each column of `X <- big_attachExtdata()` using `big_apply()`.
::::


### Similar accessor as Rcpp matrices

In case you want to develop new R functions for this format while coding in C++ (which is the case for many bigstatsr/bigsnpr functions).

```{Rcpp, eval=FALSE}
// [[Rcpp::plugins(cpp11)]]
// [[Rcpp::depends(bigstatsr, rmio)]]
#include <bigstatsr/BMAcc.h>

// [[Rcpp::export]]
NumericVector bigcolsums(Environment BM) {
  
  XPtr<FBM> xpBM = BM["address"];   // get the external pointer
  BMAcc<double> macc(xpBM);         // create an accessor to the data
  
  size_t n = macc.nrow();           // similar code as for an Rcpp::NumericMatrix
  size_t m = macc.ncol();           // similar code as for an Rcpp::NumericMatrix
  
  NumericVector res(m);
  
  for (size_t j = 0; j < m; j++) 
    for (size_t i = 0; i < n; i++)
      res[j] += macc(i, j);         // similar code as for an Rcpp::NumericMatrix
  
  return res;
}
```

For a subset of the data:

```{Rcpp, eval=FALSE}
// [[Rcpp::plugins(cpp11)]]
// [[Rcpp::depends(bigstatsr, rmio)]]
#include <bigstatsr/BMAcc.h>

// [[Rcpp::export]]
NumericVector bigcolsums2(Environment BM,
                          const IntegerVector& rowInd,
                          const IntegerVector& colInd) {
  
  XPtr<FBM> xpBM = BM["address"];   
  // accessor to a sub-view of the data -> the only line of code that should change
  SubBMAcc<double> macc(xpBM, rowInd, colInd, 1);  
  
  size_t n = macc.nrow();
  size_t m = macc.ncol();
  
  NumericVector res(m);
  
  for (size_t j = 0; j < m; j++) 
    for (size_t i = 0; i < n; i++)
      res[j] += macc(i, j); 
  
  return res;
}
```

### Some summary functions are already implemented

```{r}
(X2 <- snp_attachExtdata()$genotypes)
big_colstats(X2)      # sum and var (for each column)
big_scale()(X2)       # mean and sd (for each column)
snp_scaleBinom()(X2)  # 2 * af (mean) and sqrt(2 * af * (1 - af)) (~sd)
```

:::: {.infobox .info}
Functions starting with `big_` are part of {bigstatsr} and work for any type of FBM, while functions starting with `snp_` or `bed_` are part of {bigsnpr} and are more specific to genetic data.

There are now many functions implemented in the packages. You can find a comprehensive list of available functions on the package website [of {bigstatsr}](https://privefl.github.io/bigstatsr/reference/index.html) and [of {bigsnpr}](https://privefl.github.io/bigsnpr/reference/index.html).
::::

:::: {.infobox .question}
What is the difference between functions starting with `snp_` vs `bed_`?
::::

:::: {.infobox .caution}
To only use a subset of the data stored as an FBM, you should almost never make a copy of the data; instead, use parameters `ind.row` (or `ind.train`) and `ind.col` to apply functions to a subset of the data.
::::

```{r, include=FALSE}
rm(X); gc(); file.remove(c("tmp-data/test.bk", "tmp-data/test.rds"))
```

## Exercise

```{r, warning=FALSE}
zip <- runonce::download_file(
  "https://figshare.com/ndownloader/files/38019072",
  dir = "tmp-data", fname = "GWAS_data.zip")
unzip(zip, exdir = "tmp-data", overwrite = FALSE)
bedfile <- "tmp-data/GWAS_data.bed"
```

:::: {.infobox .exo}
Map this data with `bed()` and start exploring it a bit, e.g. what summaries you could compute, what functions you could use.
::::
